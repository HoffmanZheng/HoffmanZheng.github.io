<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Reading notes on 人间一场大梦</title>
    <link>https://hoffmanzheng.github.io/categories/reading-notes/</link>
    <description>Recent content in Reading notes on 人间一场大梦</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 21 Feb 2022 13:19:47 +0100</lastBuildDate><atom:link href="https://hoffmanzheng.github.io/categories/reading-notes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Couchbase: Blazing Fast. Surprisingly Affordable.</title>
      <link>https://hoffmanzheng.github.io/2022/database-couchbase/</link>
      <pubDate>Mon, 21 Feb 2022 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2022/database-couchbase/</guid>
      <description>Couchbase 是为企业应用设计的现代分布式文档数据库，具有强大的搜索引擎和内置的操作和分析能力。它拥有 NoSQL 的强大功能，并提供快速、高效的数据双向同步。
本篇基于 Couchbase 官网文档 介绍其数据模型、内存存储、服务与搜索、集群可用性等。
数据 Couchbase 中的每个数据都是一个键值对型的 item，它拥有在 bucket 中唯一的键，它的值可以是任何形式的二进制或者 JSON (可以包含基本/复杂的数据类型)。
{ &amp;#34;a1&amp;#34; : number, &amp;#34;a2&amp;#34; : &amp;#34;string&amp;#34;, &amp;#34;a3&amp;#34; : { // nested array  &amp;#34;b1&amp;#34; : [ number, number, number ] }, &amp;#34;a4&amp;#34; : [ // array contains objects  { &amp;#34;c1&amp;#34; : &amp;#34;string&amp;#34;, &amp;#34;c2&amp;#34; : number }, { &amp;#34;c1&amp;#34; : &amp;#34;string&amp;#34;, &amp;#34;c2&amp;#34; : number } ] } 数据模型 JSON 提供了快速的序列化与反序列化，并且是大多数 REST API 的返回类型。文档通常被认为等效于关系型数据库中的行记录，但它可以存储嵌套文档或数组，提供了更多的灵活性。</description>
    </item>
    
    <item>
      <title>分布式：[译] 基于 Redis 的分布式锁 </title>
      <link>https://hoffmanzheng.github.io/2022/distribute-redlock/</link>
      <pubDate>Wed, 19 Jan 2022 03:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2022/distribute-redlock/</guid>
      <description>原文地址：Distributed locks with Redis
当不同的进程必须以互斥的方式操作共享的资源时，分布式锁是一个非常实用的原始功能。
有很多组件库和博客都描述了如何去实现一个基于 Redis 的分布式锁管理器，但是每个库使用的实现方式不尽相同，其中许多库使用了一种简单的方式，它相比稍微复杂的设计只能提供更少的保障。
本篇尝试提供一种更加规范的算法来实现基于 Redis 的分布式锁。我们提出了一种叫做 Redlock 的算法，它可以实现一个分布式锁管理器（我们相信它比普通的单实例方法更加安全）。我们希望社区将分析它，提供反馈，并且将它作为更复杂/替代设计的基础。
实现 在描述这个算法之前，现在已经有一些可用的实现链接供参考：
 Redlock-rb (Ruby 实现). 还有一个 Redlock-rb 的分支，它为了方便分发新增了一个 gem 包，也许还有其他的。 Redlock-py (Python 实现). Pottery (Python 实现). Aioredlock (Asyncio Python 实现). Redlock-php (PHP 实现). PHPRedisMutex (further PHP 实现) cheprasov/php-redis-lock (PHP 锁的库) rtckit/react-redlock (Async PHP 实现) Redsync (Go 实现). Redisson (Java 实现). Redis::DistLock (Perl 实现). Redlock-cpp (C++ 实现). Redlock-cs (C#/.NET 实现). RedLock.net (C#/.NET 实现). 包含异步和锁的扩展支持 ScarletLock (C# .NET 实现 可配置数据源) Redlock4Net (C# .</description>
    </item>
    
    <item>
      <title>深入解析 Spring 架构与设计</title>
      <link>https://hoffmanzheng.github.io/2021/java-spring/</link>
      <pubDate>Thu, 26 Aug 2021 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2021/java-spring/</guid>
      <description>Spring 在 Java 开发中，有着不可替代的作用和地位。Spring 的目标在于让 Java EE 的开发变得更容易，这也意味着 Spring 框架的使用也应该是容易的。相比与 EJB 模型引入的过度的复杂性，Spring 提供了 IoC 容器和 AOP 支持，来降低框架对应用的 侵入性。在处理与现有优秀解决方案的关系时，Spring 不会与这些第三方的解决方案发生竞争，而是致力于为应用提供使用优秀方案的集成平台，真正地把 Spring 定位在应用平台的地位，使得自己成为一个兼容并包的开放体系。
本篇结合 《Spring技术内幕（第2版）》 从源代码的角度讲解 Spring 的各个主要功能模块的设计和实现原理。
IoC 容器的实现 如果每个对象都需要靠自身实现去获取它所 依赖 的对象，会引起代码的高度耦合并且难以测试。很多对象并不会经常发生变化，它们之间的相互依赖关系也是比较稳定的，不会随着应用的 运行状态 的改变而改变，这些特性使得这些对象依赖关系的建立和维护可以交由容器来统一完成。
IoC 容器的出现使得对象的依赖注入可以从代码中 解耦 出来，把对依赖的 控制权 从具体业务对象手中转交到平台或者框架中，有效地解决了面对对象系统设计的复杂性和系统的可测试性。
BeanFactory 对 IoC 容器的功能定义 以 BeanFactory 的实现类 XmlBeanFactory 为例，它继承了 DefaultListableBeanFactory 并在其基础上增加了功能，从名字上可以猜到，它是一个可以读取以 XML 文件方式定义的 BeanDefinition（管理了对象之间的相互依赖关系） 的 IoC 容器。
DefaultListableBeanFactory 是一个很重要的 IoC 实现，其他的 IoC 容器比如 ApplicationContext，也是通过持有或者扩展 DefaultListableBeanFactory 来获得基本的 IoC 容器的功能的。BeanDefinition 的信息来源被封装在 Resource 中，对 XML 文件定义信息的具体处理又委托给了 XmlBeanDefinitionReader 来实现。它们间相互关系的伪代码如下：</description>
    </item>
    
    <item>
      <title>Database：Redis 设计与实现</title>
      <link>https://hoffmanzheng.github.io/2021/database-redis/</link>
      <pubDate>Sat, 08 May 2021 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2021/database-redis/</guid>
      <description>Redis 是一个开源的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件，支持多种类型的数据结构和范围查询。 Redis 内置了复制（replication）、事务（transactions）和不同级别的磁盘持久化（persistence），并通过 Redis哨兵（Sentinel）和自动分区（Cluster）提供高可用性（high availability）。
本篇将结合 《Redis 设计与实现》 讲解 Redis 的内部机制、单机特性以及多机特性。
Redis 数据结构 Redis 有五种不同的 对象类型，包括字符串、列表、哈希、集合和有序集合，每种对象都用到了至少一种数据结构，这样就可以根据不同的使用场景，为对象设置不同的数据结构（内部编码）实现，从而优化对象在不同场景下的使用效率。
如上图所示，可以看到每种数据结构都有 2 种以上的 内部编码实现，例如 String 数据结构就包含了 raw、int 和 embstr 三种内部编码。同时，有些内部编码可以作为多种外部数据结构的内部实现，例如 ziplist 就是 hash、list 和 zset 共有的内部编码，而 set 的内部编码可能是 hashtable 或者 intset。
Redis 使用对象来表示数据库中的键和值，每次当我们在 Redis 数据库中新创建一个键值对时，我们至少会创建两个对象，一个键对象，一个值对象。每个对象都由一个 redisObject 结构表示：
typedef struct redisObject { unsigned type : 4; // 类型 	unsigned encoding : 4; // 编码 	void *ptr; // 指向底层实现数据结构的指针 	// ... } robj; 因为 C 语言并不具备自动内存回收功能，所以 Redis 在自己的对象系统中构建了一个 引用计数 技术实现的内存回收机制。对象的引用计数属性还带有 对象共享 的作用，不仅字符串键可以使用共享对象，那么在数据结构中嵌套了字符串对象的对象都可以使用这些共享对象。</description>
    </item>
    
    <item>
      <title>Java：并发编程实战</title>
      <link>https://hoffmanzheng.github.io/2021/java-concurrency/</link>
      <pubDate>Fri, 02 Apr 2021 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2021/java-concurrency/</guid>
      <description>在 摩尔定律 失效的今天，通过提高时钟频率来提升处理器的性能已变得越来越困难，如何高效地使用并发，充分发挥多核处理器的强大计算能力变得益发重要。操作系统的出现使得计算机可以每次运行多个程序，实现了 进程级别的并发，操作系统为每个进程分配各自的资源（比如内存），不同的进程之间可以通过一些通信机制来交换数据，包括套接字、文件、共享内存等。
线程的出现允许在同一个进程中同时存在 多个程序控制流，它们共享进程中的资源，并且可以被同时调度到多个 CPU 上运行。多线程程序通过对多核处理器的充分利用来提升系统吞吐率，然而这却会引入更多的问题：指令重排、并发修改、死锁、饥饿、活锁、上下文切换、线程调度开销等。
本篇将结合 《Java 并发编程实战》 讲解在 Java 项目中如何利用线程来提高并发程序的吞吐量或响应性，如何确保并发程序的执行与预期一致，避免安全性和活跃性问题。
并发任务的控制 在设计并发程序时，第一步就是要找出清晰的 任务边界，抽象出相互独立、可以并行执行的工作单元。大多数服务器应用程序都提供了一种自然的任务边界选择方式：以独立的客户请求为边界，主线程不断接收外部连接、分发请求并创建一个新线程来处理请求，但这种方法存在一些缺陷：
 线程生命周期的开销非常高：大量轻量级的请求会在线程的创建和销毁上消耗较多的计算资源 资源消耗：如果可运行的线程数大于可用处理器的数量，闲置线程将会占用内存，且给垃圾回收带来压力；在 CPU 忙碌的状态下再创建更多的线程反而会降低性能 稳定性：没有对可创建的线程数做一个限制，容易耗尽资源造成 OutOfMemory 异常  Executor 框架 串行执行的问题在于其糟糕的响应性和吞吐量，而 “为每个任务分配一个线程” 却产生了复杂的 资源管理 问题。为此 Java 提供了 Executor 作为 Thread 的替代，它提供了一种标准的任务执行框架，可以将任务的提交过程与实际执行过程 解耦 开来，从而无须太大的困难就可以为某种类型的任务指定和修改 执行策略。
笔者在 Java：线程池原理、源码分析 中已经介绍过线程池相关的内容，线程池通过对线程的统一分配、调优和监控等，实现了从 “为每个任务分配一个线程” 策略到基于线程池的策略的飞跃，服务器不会再创建数千个线程来争夺有限的 CPU 和内存资源，也不会再在高负载情况下失败了。
处理非正常的线程中止 在延迟任务及周期任务上，java.util.Timer 提供了基于绝对时间的调度机制， 但 Timer 在执行所有定时任务时只会创建一个线程，如果某个任务的执行时间过长，可能会影响后续的任务执行。此外如果 TimerTask 抛出一个 未检查异常，定时线程将会被 终止，Timer 也不会恢复线程的执行，而是会错误地认为整个 Timer 都被取消了。因此已经被调度但尚未执行的 TimerTask 将不会执行，新的任务也不能被调度，导致 线程泄漏。（推荐使用 DelauQueue 或者 ScheduledThreadPoolExecutor）
public class OutOfTime { public static void main(String[] args) throws Exception { Timer timer = new Timer(); timer.</description>
    </item>
    
    <item>
      <title>Database：InnoDB 存储引擎</title>
      <link>https://hoffmanzheng.github.io/2021/database-innodb/</link>
      <pubDate>Thu, 07 Jan 2021 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2021/database-innodb/</guid>
      <description>在之前的博客 Database：MySQL 数据库 中笔者已经介绍了自己对于关系型数据库 MySQL 的些许认识，但终觉不够深刻，本篇将结合 《MySQL技术内幕：InnoDB存储引擎》 讲解作为 MySQL 企业级数据库应用的第一存储引擎 InnoDB 的 核心实现和工作机制，主要内容有：缓冲池、后台线程工作机制、日志文件、锁、事务等。
MySQL 存储引擎 MySQL 数据库区别于其他数据库的最重要的一个特点就是其 插件式的表存储引擎（Pluggable Storage Engines），其提供了一系列标准的管理和服务支持，如 SQL 分析器和优化器等，这些标准与存储引擎本身无关，而存储引擎是底层物理结构的实现，每个存储引擎开发者可以按照自己的意愿来进行开发。 MySQL 数据库的体系结构如下图：
需要注意的是，存储引擎是 基于表的，而不是数据库。每个存储引擎都有各自的特点，开发者应该根据具体的应用选择适合的存储引擎，以下是一些存储引擎的简单介绍：
InnoDB 支持事务，行锁，外键，使用 MVCC 获得高并发性，实现了 SQL 的 4 种隔离级别，默认为 REPEATABLE，使用一种被称为 next-key locking 的策略来避免幻读（phantom）现象的产生，聚集索引，按主键顺序，从 MySQL 5.5.8 开始成为 MySQL 默认的存储引擎，众多互联网公司的成功应用已经证明了 InnoDB 存储引擎的高可用性、高性能以及高可扩展性。
MyISAM 不支持事务，表锁，支持全文索引，在 5.5.8 之前是默认的存储引擎，只缓存索引文件，不缓冲数据文件。
NDB 集群 存储引擎，数据全部放在内存中，主键查找速度极快，通过添加 NDB 数据存储节点（Data Node）可以线性地提高数据库性能；有一个问题值得注意，那就是 NDB 存储引擎的连接操作 JOIN 是在 MySQL 数据库层完成的，而不是在存储引擎层完成的。这意味着，复杂的连接操作需要巨大的网络开销，因此关联查询速度很慢。
Memory 数据存放于内存，数据库重启或者发生崩溃，表中的数据都将消失，使用了 哈希索引，只支持表锁，并发性能较差；MySQL 使用 Memory 存储引擎作为 临时表 来存放查询的中间结果集。
Archive 只支持 INSERT SELECT 操作，支持索引，压缩比例 1：10，非常 适合存储归档数据，如日志信息。使用行锁来实现高并发的插入操作，但并不是事务安全的引擎。</description>
    </item>
    
    <item>
      <title>Database：高性能 MySQL - 优化查询</title>
      <link>https://hoffmanzheng.github.io/2020/database-optimize-sql/</link>
      <pubDate>Tue, 22 Dec 2020 13:29:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/database-optimize-sql/</guid>
      <description>一个 MySQL 的查询任务，可以看作是一系列子任务，每个子任务都会消耗一定的时间，包括：网络、CPU 计算、生成统计信息和执行计划、锁等待等。如果要优化查询，实际上要优化其子任务，消除其中的一些子任务，减少子任务的执行次数，让子任务运行得更快。因此，了解 查询的生命周期、清楚查询的时间消耗情况对于优化查询有很大的意义。
在 Database：高性能 MySQL - 索引 篇笔者已经讲述了索引对良好的性能有着重要的影响，但如果查询写的很糟糕，即使库表结果再合理、索引再合适，也无法实现高性能。本篇基于 MySQL 5.5 版本，结合 《高性能 MySQL》 第六章 查询性能优化 的内容讲解 MySQL 如何真正地执行查询，查询高效和低效的原因何在，以及该如何对各种类型的查询，比如子查询、关联查询、排序、分组、分页等，进行合理的设计。
查询执行的基础 MySQL 客户端/服务器通信协议 一般来说不需要去理解 MySQL 通信协议的内部实现细节，只需要大致理解通信协议是如何工作的。MySQL 客户端和服务器之间的通信协议是 &amp;ldquo;半双工&amp;rdquo; 的，这意味着在任何一个时刻，要么是由服务器向客户端发送数据，要么是由客户端向服务器发送数据，这两个动作不能同时发生，无法也无须将一个消息切成小块独立来发送。
这种协议让 MySQL 通信简单快速，但也给了 MySQL 一些限制，比如：
  无法进行 流量控制，服务器必须接收客户端传来的完整查询消息才能响应，当查询语句过长超过 max_allowed_packet 时，服务器会拒绝接收并抛出错误。
  客户端必须完整地接收整个返回结果，而不能简单地只取前面几条结果，然后让服务器停止发送数据。这也是在必要的时候一定要在查询中加上 LIMIT 限制的原因。
  MySQL 通常需要等所有数据都发送给客户端后才能 释放这条查询所占用的资源，如果查询返回了一个很大的结果集，库函数会花很多时间和内存来存储所有的结果集，给服务器造成一定的压力。
  查询执行流程 MySQL 执行一个查询的过程，大体上可分为服务器层和存储引擎层两部分：
Server 层    阶段 职责     连接器 TCP 握手后服务器端验证登录用户身份   查询缓存 先检查查询缓存，如果命中则立刻返回存储在缓存中的结果   分析器 根据语法规则判断输入的 SQL 语句是否满足语法规范   优化器 选择并生成最优的执行计划   执行器 调用存储引擎的 API 执行查询    存储引擎层 负责数据的存储和提取，MySQL 插件式的存储引擎架构支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.</description>
    </item>
    
    <item>
      <title>Database：高性能 MySQL - 索引</title>
      <link>https://hoffmanzheng.github.io/2020/database-index/</link>
      <pubDate>Thu, 10 Dec 2020 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/database-index/</guid>
      <description>在之前的博客 Database：MySQL 数据库 我已经介绍了自己对 MySQL 的一些基本认识，包括它的存储引擎、数据存储结构、索引及事务等，本篇及之后的一篇将着眼于 MySQL 的性能深入探究。
索引是存储引擎用于快速找到记录的一种数据结构，它对良好的性能非常关键，它能让 MySQL 以最高效、扫描行数最少的方式找到需要的记录。本篇将结合 《高性能 MySQL》 第五章 创建高性能的索引 的内容深入分析，如何使用索引来提高 MySQL 数据库的查询性能。
本篇使用和书本相同的 MySQL 5.5 版本，使用 官方提供的测试数据库 作为示例，通过 MySQL Workbench 导入 dump 数据。
索引的类型 B-Tree 索引 在 Database：MySQL 数据库 我已经介绍过 B-Tree 索引了，这里谈下一个面试常问的问题：为什么 MySQL 的索引要使用 B+ 树而不是其他的树形结构，比如 B 树？
 B 树是一颗多叉树，相比于二叉树在相等数据量的情况下，树的高度更低，可以减少查询时的 I/O 次数。 B+ 树相比 B 树，只有叶子节点存放数据，非叶子节点只存储索引，这样就能在一张 16kb 的非叶子节点数据页中 存储更多的指针，降低树的高度，减少查询 I/O 次数，提高查询性能。 计算机层面，一次 I/O 就是磁盘的 寻道、寻点、拷贝到内存 三步操作。寻道是磁臂移动到指定磁道所需要的时间，一般在 5ms 以下；寻点是从磁道中找到数据存在的那个点，平均为半圈时间，在一个 7200 转/min 的磁盘，大概是 60,000 / 7200 / 2 = 4.</description>
    </item>
    
    <item>
      <title>JVM：体系结构与内存管理</title>
      <link>https://hoffmanzheng.github.io/2020/jvm-architecture-memory/</link>
      <pubDate>Fri, 06 Nov 2020 13:37:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/jvm-architecture-memory/</guid>
      <description>在之前的博客 Javac 编译原理与 class 文件结构 中，我有提及 Javac 编译器将 Java 源码编译成了机器可以接受的指令，解决了高级语言与底层硬件架构的耦合（现在的操作系统几乎完全向用户屏蔽了硬件，也就可以说编译器解决了高级语言与不同操作系统之间的耦合）。
JVM 屏蔽了各个计算机平台相关的软件或者硬件之间的差异，使 Java 代码可以 全平台运行。本篇以 《深入分析 Java Web 技术内幕》 第七章 JVM 体系结构与工作方式 及第八章 JVM 内存管理 的内容为参考，讲解 JVM 的基本结构、工作方式、内存分配策略及垃圾回收策略等。
JVM 体系结构 计算机与 Java 虚拟机 在了解 JVM 这台虚拟计算机之前，我们先看看一台真实的计算机的体系结构：
   计算机组成部分 功能     指令集 计算机所能识别的机器语言的命令集合   计算单元 能识别并控制指令执行的功能模块   寄存器 操作数寄存器、控制寄存器、变址寄存器等   存储单元 存储操作数和保存操作结构的单元，内存和磁盘等   寻址方式 地址位数、最小最大地址范围、地址的运行规则等    指令集 是在 CPU 中用来计算和控制计算机系统的一套指令的集合，在 CPU 设计时规定的一系列与硬件电路相配合的指令系统。可以说指令集是可以直接被机器识别的机器码，必须以二进制格式存在于计算机中，而 汇编语言 是为了让人能够更容易地记住机器指令而使用的助记符，每一条汇编指令都可以直接翻译成一个机器指令。</description>
    </item>
    
    <item>
      <title>深入分析 ClassLoader 工作机制</title>
      <link>https://hoffmanzheng.github.io/2020/java-classloader/</link>
      <pubDate>Tue, 22 Sep 2020 09:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/java-classloader/</guid>
      <description>Java 是个强类型的编程语言，一个变量的类型在编译时就已经决定了，就是最初声明它的类型， 如果想把它当成另一个类型来使用，需要先经过显式的类型转换，转换时可能会因为类型不符而抛出 ClassCastException。
本篇以 《深入分析 Java Web 技术内幕》 第六章 深入分析 ClassLoader 工作机制 的内容为参考，讲解 Java 中的类型，类加载机制，类加载错误分析 等。
Java 中的类型 如开篇所说，一个 Java 对象的类型在声明的时候就被确定了，但 Java 是面对对象的语言，有丰富的接口和抽象类，一个对象被传来传去的时候，可能就丢失了它的一些类型信息，但 Java 也像 C++ 那样是拥有 RTTI (Run-Time Type Identification) 运行时类型识别 特性的语言。在任何时刻，任何一个对象都清楚地知道自己的具体类型（可以通过反射获取）。
不知道大家有没有想过，Java 中的对象是如何被创造出来的，创造时是否又遵循了一个怎样的规则。其实 Java 中的对象都是根据各自的说明书构建出来的，这个说明书信息就是在 Javac 编译原理与 class 文件结构 中生成的类的 class 字节码文件之中，这些字节码文件又被存储在永久代 (Permenent Generation Java 7 之前) / 元空间 (MetaSpace Java 8 之后) 之中。
当需要创建一个对象时，就会将这个创建任务委托给类加载器来完成，类加载器会找到指定的 class 字节码文件，根据说明书来装配出一个需要的对象。因此任何一个 Java 对象，在运行时都清楚的知道自己是由哪个类的字节码装配出来的，都可以通过 getClass() / instanceof 来获取自己的具体类型。
类加载机制 JVM 类加载机制分为五个部分：加载、验证、准备、解析、初始化，如下所示：
   类加载阶段 作用     加载 生成 Class 对象，作为方法区这个类的各种数据入口   验证 确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求   准备 为类变量分配内存空间，并设置变量初始值，非 finanl 是0，final 会赋值   解析 虚拟机将常量池中的符号引用替换为直接引用的过程   初始化 执行类构造器方法（静态语句块）    ClassLoader 类加载器 类加载器 ClassLoader 在 JDK 源码中的 rt.</description>
    </item>
    
    <item>
      <title>Javac 编译原理与 class 文件结构</title>
      <link>https://hoffmanzheng.github.io/2020/java-compile/</link>
      <pubDate>Sat, 05 Sep 2020 09:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/java-compile/</guid>
      <description>JVM 让 Java 成为了一次编译，到处运行，具有平台无关性的高级语言。要让 Java 代码跑在 JVM 中少不了 Javac 编译器，它把人类能理解的 Java 源代码语言翻译成 JVM 容易理解的字节码（将 .java 文件转换成 .class 文件）。某种意义上来说，Javac 编译器的存在使 Java 语言向开发者屏蔽了很多与机器相关的细节，JVM 使 Java 语言的执行和平台无关，这才成就了 Java 的繁荣。
本篇以 《深入分析 Java Web 技术内幕》 第四章 Javac 编译原理 及第五章 深入 class 文件结构 的内容为参考，讲解 Javac 编译器的基本结构，Javac 的工作原理，class 文件结构等。
Javac 编译器的基本结构 Javac 编译器的作用就是将符合 Java 语言规范的源代码转化成符合 Java 虚拟机规范的 Java 字节码，是从一个语言规范到另一个语言规范的转化，这大概需要以下几个步骤：
   编译过程 步骤     词法分析过程 识别源代码中的语法关键词，形成 Token 流   语法分析过程 检查关键词组合是否符合 Java 语言规范，形成一个抽象语法树   语义分析过程 把一些难懂的、复杂的语法转化成更加简单的语法，形成一个注解过后的抽象语法树   字节码生成 根据注解过后的抽象语法树生成字节码    词法分析过程 在 Javac 编译一个类之前，会先一个字节一个字节地读取源代码，找出其中的语法关键词，如 if、else、for、while 等，最后形成一些规范化的 Token 流，就像在人类语言中，分辨一句话中的动词、名词、标点符号等。</description>
    </item>
    
    <item>
      <title>深入分析 Java Web 中的中文编码问题</title>
      <link>https://hoffmanzheng.github.io/2020/java-encode/</link>
      <pubDate>Sat, 29 Aug 2020 09:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/java-encode/</guid>
      <description>作为非英语国家程序员，编码问题是我们一直都绕不过去的一道坎。
本篇以 《深入分析 Java Web 技术内幕》 第三章 深入分析 Java Web 中的中文编码问题 的内容为参考，讲解常见的编码格式、Java 中的编解码、Java Web 中的编解码，及常见乱码问题分析等。
计算机中存储信息的最小单元是 1 个字节，即 8 bits，所以能表示的字符范围是 0~255 个，而我们人类的语言太多，表示这些语言的符号太多，因而必须要经过一些翻译工作，才能让计算机理解我们的语言。这个翻译工作就是从 char 到 byte 的编码过程。
常见的编码格式 ASCⅡ 码 使用一个字节的低 7 位表示，范围为 0~127 共 128 个，包括了英文大小写字母，数字及常用的数学符号。0~31 是控制字符如换行、回车、空字符等，32~126 是打印字符，127 为删除。
IOS-8859-1 ASCⅡ 码的 128 个字符显然是不够用的，ISO 组织在 ASCⅡ 码基础上扩展出 ISO-8859-1 至 ISO-8859-15，其中 ISO-8859-1 涵盖了大多数西欧语言字符，应用最广泛。ISO-8859-1 仍然是 单字节编码，总共能表示 256 个字符。
GB 2312 《信息交换用汉字编码字符集》，双字节编码，范围为 A1~F7，包含 682 个符号和 6763 个汉字。
GBK 《汉字内码扩展规范》扩展了 GB2312，加入更多的汉字，编码范围是 8140~FEFE，能表示 21003 个汉字，兼容 GB 2312。也就是说用 GB 2312 编码的汉字可以用 GBK 来解码且不会用乱码。</description>
    </item>
    
    <item>
      <title>深入分析 Java I/O 的工作机制</title>
      <link>https://hoffmanzheng.github.io/2020/java-io/</link>
      <pubDate>Mon, 17 Aug 2020 09:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/java-io/</guid>
      <description>I/O 是任何编程语言都无法回避的问题，它是人机交互中机器获取和交换信息的主要渠道，可以说大部分 Web 应用系统的瓶颈都是 I/O 瓶颈。
本篇以 《深入分析 Java Web 技术内幕》 第二章 深入分析 Java I/O 的工作机制 的内容为参考，讲解 Java I/O 类库、磁盘 I/O、网络 I/O、NIO 工作机制等。
Java I/O 类库的基本架构 基于字节的 I/O 操作接口 无论是磁盘还是网络传输，最小的存储单元都是字节，而不是字符，所以 I/O 操作的都是字节而不是字符，Java 中基于字节的 I/O 操作接口输入和输出分别是 InputStream 和 OutputStream，其类层次关系如下图所示。
需要明确的是，字节流从哪里读或是写入到哪里，操作数据的方式是可以组合使用的，如：
OutputStream outputStream = new BufferedOutputStream(new FileOutputStream(new File(&amp;#34;pathName&amp;#34;))); 基于字符的 I/O 操作接口 虽然 I/O 操作的都是字节，但我们在程序中通常都是操作字符，为了方便 JDK 也提供了一个直接写字符的 I/O 接口 Reader 和 Writer，这样我们就可以直接将字符写入到文件或者网络流去。
例如写字符的操作接口为 void write(char[] cbuf, int off, int len)
字节与字符的转化接口 字符在写入文件持久化或者网络传输之前，都需要先经过编码转换，下图中 InputStreamReader 就是从字节到字符的转化桥梁，在初始化时需要指定编码字符集，否则会采用操作系统默认的字符集，很可能出现乱码问题。具体的编码解码过程可以查看：深入分析 Java Web 中的中文编码问题</description>
    </item>
    
    <item>
      <title>深入 Web 请求过程</title>
      <link>https://hoffmanzheng.github.io/2020/dns-cdn/</link>
      <pubDate>Sun, 26 Jul 2020 09:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/dns-cdn/</guid>
      <description>由于之前找工作，刚来上海挺多事，些久没写博客；至此打算新开一个 “学习录” 系列（以读书笔记和实战心得为主），记录自己 Java 学习路上的收获，共勉。
以 《深入分析 Java Web 技术内幕》 第一章 深入 Web 请求过程的内容为参考，此篇讲解游览器缓存、DNS 域名解析的过程和 CDN 工作机制。
游览器缓存 缓存可以减少游览器向服务器请求资源的次数，减少网络延时，加快页面响应速度，减少服务器压力。下图中 size 不为 0 的请求就是没有使用缓存。
Memory Cache 会将资源暂时缓存到内存中，在关闭游览器后会释放掉这部分内存空间。受限于计算机内存的大小，当内存使用率高的时候，资源大概率会被缓存到 Disk Cache，它可以长时效的在硬盘中缓存资源。
Cache-Control / Pragma 我们在游览一个页面时发现有异常，通常考虑的就是是不是游览器做的缓存，这个时候可以按 Ctrl + F5 来重新请求到没有缓存的页面。这个组合键会直接向目标 URL 发送请求，而不会使用游览器缓存的数据；它会在 HTTP 的请求头中增加一些请求头，告诉服务器我们要获取最新的数据而不是缓存（以此也可以跳过前端部署的缓存服务器）。
 对 HTTP 请求头不太熟悉的同学可以先参考下我的计网学习笔记：Net：计算机网络读书笔记。
 使用 Ctrl + F5 组合键后在 HTTP 请求头中增加了两项 Pragma:no-cache 和 Cache-Control:no-cache，其字段可选值如下表所示：
   可选值 说明     Private 所有内容都将被缓存，在响应头中设置   Private 内容只缓存到私有缓存中，在响应头中设置   no-cache 所有内容都不会被缓存，在请求头和响应头中设置   no-store 所有内容都不会被缓存到缓存或 Internet 临时文件中，在响应头中设置   must-revalidation/proxy-revalidation 如果设置的内容失效，请求必须发送到服务器 / 代理以进行重新验证，在请求头中设置   max-age=xxx 缓存的内容将在 xxx 秒后失效，这个选项只在 HTTP 1.</description>
    </item>
    
  </channel>
</rss>
