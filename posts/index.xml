<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 人间一场大梦</title>
    <link>https://hoffmanzheng.github.io/posts/</link>
    <description>Recent content in Posts on 人间一场大梦</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Nov 2022 13:19:47 +0100</lastBuildDate><atom:link href="https://hoffmanzheng.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>HTTP/2：漫谈 RFC 7540</title>
      <link>https://hoffmanzheng.github.io/2022/net-http-2/</link>
      <pubDate>Wed, 09 Nov 2022 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2022/net-http-2/</guid>
      <description>HTTP/2 在引入头部字段压缩和允许单连接并发交换后，使更加高效的网络资源使用和更低的接收延迟成为可能。同时也引入了从服务端到客户端的主动推送。本篇结合 RFC 7540 谈谈 HTTP version 2。
前言 超文本传输协议是一个大获成功的协议，尽管如此，HTTP/1.1 使用的基础传输却有着会对当下的 应用性能 造成不利影响的特性。具体地讲，HTTP/1.0 只允许在单个 TCP 连接中处理 一个 请求，在 HTTP/1.1 新增请求管道后，也只实现了部分的并发请求，并仍遭受着头部阻塞。因此，HTTP/1.0 和 HTTP/1.1 的客户端为了实现并发并降低延迟，需要使用多个与服务端的连接来发送多个请求。此外，HTTP 头部字段经常是重复且冗余的，导致了不必要的网络流量，且拥塞窗口会被快速填充。这将在单个 TCP 连接处理多个请求时导致过度的延迟。
HTTP/2 通过在基础连接中定义一个更优的 HTTP 语义映射来处理这些问题。具体地，它允许在同个连接中多个请求和响应消息的交织，并对 HTTP 头部字段采用了高效的编码。它还支持请求的优先级，让一些更重要的请求能够更快地完成，以此来提升性能。生成的协议对网络更加友好，因为相比 HTTP/1.x 只需使用更少的连接。这也意味着与其他流和长连接之间更少的竞争，反过来能更好地利用可用的网络容量。
HTTP 2 协议概览 HTTP/2 给 HTTP 语义提供了一个改良的传输，它支持 HTTP/1.1 的所有核心特征，但旨在某些方面变得更加高效。HTTP/2 的基础协议单元是一个框架 frame，每个框架类型服务一个不同的目的。例如，HEADERS 和 DATA 框架组成了 HTTP 请求和响应的基础，其他框架类型如 SETTINGS、WINDOW_UPDATE 和 PUSH_PROMISE 被用来支持 HTTP/2 的其他特性。
请求的多路复用通过让每个 HTTP 请求/响应与它自己的流交换来实现。流是 各自独立 的，因此一个被阻塞的请求或响应不会阻止其他流的进程。流的控制和优先级使使用多路的流成为可能。流的控制保证了被接收者使用的数据被传输了。优先级保证了有限的资源能被首先引导至更重要的流上。
HTTP/2 增加了一个新的交互模式，借此一个服务可以向客户端推送响应。服务推送允许一个服务在权衡网络使用和潜在的延迟收益后，向客户端任意的发送（预计它将会需要的）数据。服务端通过合成一个发送 PUSH_PROMISE 框架的请求来完成这个。随后服务端就能在一个独立的流中给这个合成的请求发送一个响应。因为在连接中使用的 HTTP 头部字段可能包含了大量多余的数据，包含它们的框架可以被压缩。这对通常情况下的请求大小有着特殊的优势，且允许许多请求被压缩在一个包里。
HTTP 2 连接 一个 HTTP/2 连接是一个运行在 TCP 连接之上的应用层协议。客户端是 TCP 连接的初始化器。HTTP/2 使用与 HTTP/1.</description>
    </item>
    
    <item>
      <title>重构：改善既有代码的设计</title>
      <link>https://hoffmanzheng.github.io/2022/code-refactor/</link>
      <pubDate>Mon, 02 May 2022 03:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2022/code-refactor/</guid>
      <description>不知道大家有没有发现，编程活动的许多方面，都很难一次做对。可能是对代码的进一步理解，亦或是用户需求的又一次变化，当前的设计可能不再适合于需求。如果容许瑕疵存在，并进一步累积，代码就会变得越来越 复杂。在这之后对代码进行的理解、修改或调试，就会变得益发困难起来。
所谓重构，是在 不改变 代码外在行为的前提下，对程序内部结构的修改，对其设计的改进。虽然重构并不是一件做起来轻松的事，它却能使软件工程拥有更长的生命力。本篇结合 《重构 (第 2 版)》 从一个开发者的角度讲讲重构，包括但不限于：察觉代码的坏味道、如何安全地重构以及几种重构的场景。本篇不会事无巨细地介绍所有的重构手法，而旨在指出一些值得参考的重构思想。
先聊聊测试 重构并 不总是安全 的，正如代码的其他改动一样，重构也有可能引入新的 bug。如果当前的工程项目还没有覆盖自动测试，那笔者极力推荐在开始重构之前，先补全对于待重构代码的单元测试。
在没有自动测试的情况下，开发者不得不频繁地在做出改动后手动调试测试程序的功能。这将花费很多时间和精力，并且也不够安全。编写 自动测试，可以让计算机来帮我们执行规律且重复的测试动作，测试代码片段对传入参数做出的响应是否符合预期或发生变化。在每一次完成代码重构后，都可以从容地运行测试，来帮助我们检查代码的行为是否受到了影响。
笔者曾就职于国内某民营企业，其部门的项目代码竟没有任何的测试代码，开发者只能在功能上线后再进行手动测试。就算这样，线上事故也频频发生，既存在新上线的功能无法达到预期的问题，也会有老的功能受到代码修改带来的影响。其实有很多的事故，在有了充足的自动测试后，都能被及早的发现，并且可以在很大程度上避免将这些问题暴露给我们的用户。
代码的可读性 作为优秀的程序员，我们的目的从来不只是写出计算机可以理解的代码，而是写出人类容易理解的代码。大多数开发者都认为，代码被阅读和被修改的次数远远多于它被编写的次数，而保持代码易读、易修改是重构努力的方向之一。
提炼函数 旧的项目大多都存在一些 重复代码，在阅读时得加倍仔细，留意它们之间细微的差异，在修改时也必须找出所有的副本，这让开发者痛苦不已。对此，通常我们需要先尝试移动语句，将相似的部分放在一起，再提炼成一个函数并给它一个具有意义的名字。
往往活得长的程序，其中的函数都比较短。可能初学者会觉得小函数的程序满是无穷无尽的委托调用，但和这种程序共处一段时间后，就能体会到它带来的好处 —— 更好的阐释力、且更易于分享。小函数让人易于理解的关键在于良好的命名，使代码的阅读者可以通过名字快速了解函数的作用。
每当感觉需要用 注释 来说明点什么的时候，我们也可以把需要说明的东西写进一个独立函数中，并以其用途（而非实现手法）命名。注释通常能指出代码用途和实现手法之间的语义差异。如果代码前方有一行注释，可能就是在提醒你：可以将这段代码替换成一个函数，并在注释的基础上给这个函数命名。
有的开发者会在代码复用时使用提炼函数，但更为合理的是，我们可以用提炼函数将代码的 意图 与实现分开。如果一段代码需要花一段时间游览才能弄明白它到底在干什么，就应该将其提炼到一个函数中，并根据它所做的事为其命名。提炼函数的示例代码如下：
function printOwing(invoice) { let outstanding = 0; console.log(&amp;#34;***********************&amp;#34;); console.log(&amp;#34;**** Customer Owes ****&amp;#34;); console.log(&amp;#34;***********************&amp;#34;); // calculate outstanding  for (const o of invoice.orders) { outstanding += o.amount; } // record due date  const today = Clock.today; invoice.dueDate = new Date(today.</description>
    </item>
    
    <item>
      <title>Devops：[译] 日志聚合系统 Grafana Loki </title>
      <link>https://hoffmanzheng.github.io/2022/devops-loki/</link>
      <pubDate>Thu, 21 Apr 2022 03:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2022/devops-loki/</guid>
      <description>原文地址：The original design doc of Loki
本篇旨在解释 Grafana Loki 服务的动机和设计。本文档并不试图深入描述设计的每一个可能的细节，但希望能解释关键点，并让我们提前发现任何明显的错误。本文档不仅回答我们如何打算构建它的问题，而且还回答我们为什么构建它，它将用来做什么，以及谁将使用它的问题。
背景与动机 事件响应 &amp;amp; 上下文切换 虽然 Metrics 和 Alerts 可以在时间序列上预警发生的事件，但它们只能用来暴露预先定义好的行为。为了得到事件的全貌，工程师通常通过日志来获取更多的细节信息。
通常事件发生时会首先引起警报，并伴随着仪表盘出现特定的表象。在定位异常来源的具体服务或实例前，工程师会尝试在服务/实例的日志中寻找其根本原因。而现状是，Metrics 和 logs 被存储在两个分离的系统中，工程师需要将查询从一种语言和接口转换到另一个。因此设计 Loki 的第一个设想是减少在 logs 和 metrics 之间切换上下文的开销，来更快地响应事件而改善用户体验。
现存的解决方案 日志聚合并不是一个新的概念，就像时序监控一样，有许多 SaaS 供应商和开源项目都在竞争这个市场。几乎所有的现存方案都使用了全文搜索系统来索引日志，乍一看，这似乎是显而易见的解决方案，具有丰富而强大的功能集，允许进行复杂的查询。
而这些现存方案因太过复杂而难以扩展，资源占用高，操作困难。如上所述，一种越来越普遍的模式是结合使用时间序列监控和日志聚合——因此查询工具提供的灵活性和复杂性通常 没有 被使用； 大多数查询只关注时间范围和一些简单的参数（主机、服务等）。 使用这些系统进行日志聚合类似于使用大锤来敲开坚果。
现有系统的挑战和运营开销已导致许多买家落入 SaaS 运营商手中。 因此，设计 Loki 的第二个设想是，可以在易于操作和查询语言的复杂性之间进行不同的权衡，并且使其便于操作。
成本效益 随着向 SaaS 日志聚合的迁移，此类系统的过高成本越发突显。 这种成本不仅来自用于实现全文搜索的技术 —— 对倒排索引进行扩展和分片也很困难； 要么写入触及的每个分片，要么必须从每个分片读取；此外操作也具有一定的复杂性。
买家寻求日志聚合系统的的一个常见经验是，在收到超出他们预算的基于现有日志负载的初始报价后，转向工程师并要求他们减少日志记录。 由于日志记录的存在是为了覆盖意外的错误（见上文），工程师的典型反应是难以置信 —— “如果我必须知道我该记录什么，那么记录日志又有什么意义？”。
最近出现的一些系统在这点上提供了不同的权衡。 Peter Bourgon 的开源 OKLOG 项目（现已存档）避开了基于时间的所有形式的索引，并采用最终一致的基于网格的分发策略。 这两个设计决策提供了巨大的成本节约和从根本上更简单的操作，但我们认为不符合我们的其他设计要求 —— 查询不够表现力且过于昂贵。 然而，我们确实认识到这是一个有吸引力的本地解决方案。
因此第三个设想是，一个显着更具成本效益的解决方案，具有稍微不同的索引权衡，将是一个非常大的问题&amp;hellip;&amp;hellip;
Kubernetes 一个有趣的需要考虑的问题是日志记录如何适用于现代云原生/微服务/容器化的工作负载中。 现在的标准模式是应用程序只需将日志写入 STDOUT 或 STDERR。 Kubernetes 和 Docker 等平台以此为基础提供有限的日志聚合功能； 日志被存储在本地节点上，可以使用标签选择器按需获取和聚合。</description>
    </item>
    
    <item>
      <title>Couchbase: Blazing Fast. Surprisingly Affordable.</title>
      <link>https://hoffmanzheng.github.io/2022/database-couchbase/</link>
      <pubDate>Mon, 21 Feb 2022 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2022/database-couchbase/</guid>
      <description>Couchbase 是为企业应用设计的现代分布式文档数据库，具有强大的搜索引擎和内置的操作和分析能力。它拥有 NoSQL 的强大功能，并提供快速、高效的数据双向同步。
本篇基于 Couchbase 官网文档 介绍其数据模型、内存存储、服务与搜索、集群可用性等。
数据 Couchbase 中的每个数据都是一个键值对型的 item，它拥有在 bucket 中唯一的键，它的值可以是任何形式的二进制或者 JSON (可以包含基本/复杂的数据类型)。
{ &amp;#34;a1&amp;#34; : number, &amp;#34;a2&amp;#34; : &amp;#34;string&amp;#34;, &amp;#34;a3&amp;#34; : { // nested array  &amp;#34;b1&amp;#34; : [ number, number, number ] }, &amp;#34;a4&amp;#34; : [ // array contains objects  { &amp;#34;c1&amp;#34; : &amp;#34;string&amp;#34;, &amp;#34;c2&amp;#34; : number }, { &amp;#34;c1&amp;#34; : &amp;#34;string&amp;#34;, &amp;#34;c2&amp;#34; : number } ] } 数据模型 JSON 提供了快速的序列化与反序列化，并且是大多数 REST API 的返回类型。文档通常被认为等效于关系型数据库中的行记录，但它可以存储嵌套文档或数组，提供了更多的灵活性。</description>
    </item>
    
    <item>
      <title>分布式：[译] 基于 Redis 的分布式锁 </title>
      <link>https://hoffmanzheng.github.io/2022/distribute-redlock/</link>
      <pubDate>Wed, 19 Jan 2022 03:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2022/distribute-redlock/</guid>
      <description>原文地址：Distributed locks with Redis
当不同的进程必须以互斥的方式操作共享的资源时，分布式锁是一个非常实用的原始功能。
有很多组件库和博客都描述了如何去实现一个基于 Redis 的分布式锁管理器，但是每个库使用的实现方式不尽相同，其中许多库使用了一种简单的方式，它相比稍微复杂的设计只能提供更少的保障。
本篇尝试提供一种更加规范的算法来实现基于 Redis 的分布式锁。我们提出了一种叫做 Redlock 的算法，它可以实现一个分布式锁管理器（我们相信它比普通的单实例方法更加安全）。我们希望社区将分析它，提供反馈，并且将它作为更复杂/替代设计的基础。
实现 在描述这个算法之前，现在已经有一些可用的实现链接供参考：
 Redlock-rb (Ruby 实现). 还有一个 Redlock-rb 的分支，它为了方便分发新增了一个 gem 包，也许还有其他的。 Redlock-py (Python 实现). Pottery (Python 实现). Aioredlock (Asyncio Python 实现). Redlock-php (PHP 实现). PHPRedisMutex (further PHP 实现) cheprasov/php-redis-lock (PHP 锁的库) rtckit/react-redlock (Async PHP 实现) Redsync (Go 实现). Redisson (Java 实现). Redis::DistLock (Perl 实现). Redlock-cpp (C++ 实现). Redlock-cs (C#/.NET 实现). RedLock.net (C#/.NET 实现). 包含异步和锁的扩展支持 ScarletLock (C# .NET 实现 可配置数据源) Redlock4Net (C# .</description>
    </item>
    
    <item>
      <title>Ruby：版本管理 RVM、Gem 与 Bundler</title>
      <link>https://hoffmanzheng.github.io/2021/ruby-bundler/</link>
      <pubDate>Sun, 10 Oct 2021 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2021/ruby-bundler/</guid>
      <description>本篇介绍在 Ruby 项目中版本及包管理的工程实践，包括使用 RubyGems 管理 Ruby 的组件，使用 Bundler 来解决项目中 gem 组件的依赖问题，使用 RVM 管理不同版本的 Ruby 环境等。
推荐阅读：
 Bundler 到底是怎么工作的(暨 Ruby 依赖管理历史回顾) Ruby Gemfile 详解  RubyGems Ruby 主要通过 require 函数来引入外部的库文件，参数可以传文件名，相对路径或是绝对路径。当参数是文件名时，Ruby 会去 $LOAD_PATH 这个全局变量定义的路径中搜索库文件。
$ ruby -e &amp;#34;puts $:&amp;#34; /usr/local/lib/ruby/site_ruby/2.7.0 /usr/local/lib/ruby/site_ruby/2.7.0/x86_64-darwin20 /usr/local/lib/ruby/site_ruby /usr/local/lib/ruby/vendor_ruby/2.7.0 /usr/local/lib/ruby/vendor_ruby/2.7.0/x86_64-darwin20 /usr/local/lib/ruby/vendor_ruby /usr/local/Cellar/ruby@2.7/2.7.4/lib/ruby/2.7.0 /usr/local/Cellar/ruby@2.7/2.7.4/lib/ruby/2.7.0/x86_64-darwin20 $LOAD_PATH 是一个数组变量，里面存放依赖路径字符串，可以看到其中的目录可以分成三大类：
 site_ruby 默认优先级最高，安装本机相关库 vendor_ruby 操作系统供应商进行定制用的，一般为空 2.7.4 ruby 标准库目录，比如 date, csv 库  require 会按照 $LOAD_PATH 数组里面的路径顺序进行查找，找到了就不继续往下找了。
RubyGems 是用来寻找并管理 Ruby 组件的工具，让你可以轻松下载别人的代码，它重写了 require 函数的实现，并将 gem 安装到和 site_ruby 平级的 gems 目录下。gem 工具允许你用一个单一命令完成下载以及安装，允许你一键卸载，并且中心化管理所有安装了的库。</description>
    </item>
    
    <item>
      <title>深入解析 Spring 架构与设计</title>
      <link>https://hoffmanzheng.github.io/2021/java-spring/</link>
      <pubDate>Thu, 26 Aug 2021 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2021/java-spring/</guid>
      <description>Spring 在 Java 开发中，有着不可替代的作用和地位。Spring 的目标在于让 Java EE 的开发变得更容易，这也意味着 Spring 框架的使用也应该是容易的。相比与 EJB 模型引入的过度的复杂性，Spring 提供了 IoC 容器和 AOP 支持，来降低框架对应用的 侵入性。在处理与现有优秀解决方案的关系时，Spring 不会与这些第三方的解决方案发生竞争，而是致力于为应用提供使用优秀方案的集成平台，真正地把 Spring 定位在应用平台的地位，使得自己成为一个兼容并包的开放体系。
本篇结合 《Spring技术内幕（第2版）》 从源代码的角度讲解 Spring 的各个主要功能模块的设计和实现原理。
IoC 容器的实现 如果每个对象都需要靠自身实现去获取它所 依赖 的对象，会引起代码的高度耦合并且难以测试。很多对象并不会经常发生变化，它们之间的相互依赖关系也是比较稳定的，不会随着应用的 运行状态 的改变而改变，这些特性使得这些对象依赖关系的建立和维护可以交由容器来统一完成。
IoC 容器的出现使得对象的依赖注入可以从代码中 解耦 出来，把对依赖的 控制权 从具体业务对象手中转交到平台或者框架中，有效地解决了面对对象系统设计的复杂性和系统的可测试性。
BeanFactory 对 IoC 容器的功能定义 以 BeanFactory 的实现类 XmlBeanFactory 为例，它继承了 DefaultListableBeanFactory 并在其基础上增加了功能，从名字上可以猜到，它是一个可以读取以 XML 文件方式定义的 BeanDefinition（管理了对象之间的相互依赖关系） 的 IoC 容器。
DefaultListableBeanFactory 是一个很重要的 IoC 实现，其他的 IoC 容器比如 ApplicationContext，也是通过持有或者扩展 DefaultListableBeanFactory 来获得基本的 IoC 容器的功能的。BeanDefinition 的信息来源被封装在 Resource 中，对 XML 文件定义信息的具体处理又委托给了 XmlBeanDefinitionReader 来实现。它们间相互关系的伪代码如下：</description>
    </item>
    
    <item>
      <title>Database：Redis 设计与实现</title>
      <link>https://hoffmanzheng.github.io/2021/database-redis/</link>
      <pubDate>Sat, 08 May 2021 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2021/database-redis/</guid>
      <description>Redis 是一个开源的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件，支持多种类型的数据结构和范围查询。 Redis 内置了复制（replication）、事务（transactions）和不同级别的磁盘持久化（persistence），并通过 Redis哨兵（Sentinel）和自动分区（Cluster）提供高可用性（high availability）。
本篇将结合 《Redis 设计与实现》 讲解 Redis 的内部机制、单机特性以及多机特性。
Redis 数据结构 Redis 有五种不同的 对象类型，包括字符串、列表、哈希、集合和有序集合，每种对象都用到了至少一种数据结构，这样就可以根据不同的使用场景，为对象设置不同的数据结构（内部编码）实现，从而优化对象在不同场景下的使用效率。
如上图所示，可以看到每种数据结构都有 2 种以上的 内部编码实现，例如 String 数据结构就包含了 raw、int 和 embstr 三种内部编码。同时，有些内部编码可以作为多种外部数据结构的内部实现，例如 ziplist 就是 hash、list 和 zset 共有的内部编码，而 set 的内部编码可能是 hashtable 或者 intset。
Redis 使用对象来表示数据库中的键和值，每次当我们在 Redis 数据库中新创建一个键值对时，我们至少会创建两个对象，一个键对象，一个值对象。每个对象都由一个 redisObject 结构表示：
typedef struct redisObject { unsigned type : 4; // 类型 	unsigned encoding : 4; // 编码 	void *ptr; // 指向底层实现数据结构的指针 	// ... } robj; 因为 C 语言并不具备自动内存回收功能，所以 Redis 在自己的对象系统中构建了一个 引用计数 技术实现的内存回收机制。对象的引用计数属性还带有 对象共享 的作用，不仅字符串键可以使用共享对象，那么在数据结构中嵌套了字符串对象的对象都可以使用这些共享对象。</description>
    </item>
    
    <item>
      <title>Java：并发编程实战</title>
      <link>https://hoffmanzheng.github.io/2021/java-concurrency/</link>
      <pubDate>Fri, 02 Apr 2021 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2021/java-concurrency/</guid>
      <description>在 摩尔定律 失效的今天，通过提高时钟频率来提升处理器的性能已变得越来越困难，如何高效地使用并发，充分发挥多核处理器的强大计算能力变得益发重要。操作系统的出现使得计算机可以每次运行多个程序，实现了 进程级别的并发，操作系统为每个进程分配各自的资源（比如内存），不同的进程之间可以通过一些通信机制来交换数据，包括套接字、文件、共享内存等。
线程的出现允许在同一个进程中同时存在 多个程序控制流，它们共享进程中的资源，并且可以被同时调度到多个 CPU 上运行。多线程程序通过对多核处理器的充分利用来提升系统吞吐率，然而这却会引入更多的问题：指令重排、并发修改、死锁、饥饿、活锁、上下文切换、线程调度开销等。
本篇将结合 《Java 并发编程实战》 讲解在 Java 项目中如何利用线程来提高并发程序的吞吐量或响应性，如何确保并发程序的执行与预期一致，避免安全性和活跃性问题。
并发任务的控制 在设计并发程序时，第一步就是要找出清晰的 任务边界，抽象出相互独立、可以并行执行的工作单元。大多数服务器应用程序都提供了一种自然的任务边界选择方式：以独立的客户请求为边界，主线程不断接收外部连接、分发请求并创建一个新线程来处理请求，但这种方法存在一些缺陷：
 线程生命周期的开销非常高：大量轻量级的请求会在线程的创建和销毁上消耗较多的计算资源 资源消耗：如果可运行的线程数大于可用处理器的数量，闲置线程将会占用内存，且给垃圾回收带来压力；在 CPU 忙碌的状态下再创建更多的线程反而会降低性能 稳定性：没有对可创建的线程数做一个限制，容易耗尽资源造成 OutOfMemory 异常  Executor 框架 串行执行的问题在于其糟糕的响应性和吞吐量，而 “为每个任务分配一个线程” 却产生了复杂的 资源管理 问题。为此 Java 提供了 Executor 作为 Thread 的替代，它提供了一种标准的任务执行框架，可以将任务的提交过程与实际执行过程 解耦 开来，从而无须太大的困难就可以为某种类型的任务指定和修改 执行策略。
笔者在 Java：线程池原理、源码分析 中已经介绍过线程池相关的内容，线程池通过对线程的统一分配、调优和监控等，实现了从 “为每个任务分配一个线程” 策略到基于线程池的策略的飞跃，服务器不会再创建数千个线程来争夺有限的 CPU 和内存资源，也不会再在高负载情况下失败了。
处理非正常的线程中止 在延迟任务及周期任务上，java.util.Timer 提供了基于绝对时间的调度机制， 但 Timer 在执行所有定时任务时只会创建一个线程，如果某个任务的执行时间过长，可能会影响后续的任务执行。此外如果 TimerTask 抛出一个 未检查异常，定时线程将会被 终止，Timer 也不会恢复线程的执行，而是会错误地认为整个 Timer 都被取消了。因此已经被调度但尚未执行的 TimerTask 将不会执行，新的任务也不能被调度，导致 线程泄漏。（推荐使用 DelauQueue 或者 ScheduledThreadPoolExecutor）
public class OutOfTime { public static void main(String[] args) throws Exception { Timer timer = new Timer(); timer.</description>
    </item>
    
    <item>
      <title>Java：异常处理与日志记录</title>
      <link>https://hoffmanzheng.github.io/2021/java-exception-log/</link>
      <pubDate>Wed, 24 Mar 2021 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2021/java-exception-log/</guid>
      <description>在开发 Java 项目中通常依赖 Eclipse/IDEA 等集成开发工具的 Debug 调试来追踪解决 Bug，而在没有调试工具的测试、生产环境（一般也不允许远程调试）往往通过日志的轨迹 快速定位并解决线上问题。 但如果日志输出不好，不仅无法辅助定位问题反而可能会影响到程序的运行性能和稳定性。
本篇将结合 阿里巴巴《Java 开发手册（嵩山版）》、 Log4j 2.x 官方文档、 Takipi 日志相关文章 讲解在项目中如何优雅地处理异常以及高效且有效地记录日志。
Java 的异常处理 错误码 阿里巴巴《Java 开发手册（嵩山版）》 中有关错误码给出了以下几点指导：
 错误码就像康熙字典中的生僻字一样，用词似乎精准，但是字典不容易随身携带并且简单易懂。1）错误码必须能够快速知晓 错误来源，可快速判断是谁的问题。 2）错误码必须能够进行清晰地比对（代码中容易 equals）。 3） 错误码有利于团队快速对错误原因达到 一致认知 错误码分成两个部分：错误产生来源 + 四位数字编号 ，可参考手册中的附表（避免随意定义新的错误码），用于快速溯源。将来源于客户、当前系统、第三方服务的错误快速 区分。在无法具体确定的错误场景中，可直接使用 宏观错误码，比如 A0001（用户端错误）、B0001（系统执行出错）、C0001（调用第三方服务出错） 错误码不能直接输出给用户作为提示信息使用。堆栈（stack_trace）、错误信息（error_message）、错误码（ error_code）、提示信息（ user_tip）是一个有效关联并互相转义的和谐整体，但是 请勿互相越俎代庖。错误码之外的业务独特信息由 error_message 来承载，而不是让错误码本身涵盖过多具体业务属性 在获取第三方服务错误码时，向上抛出允许 本系统转义，由 C 转为 B，并且在错误信息上带上原有的第三方错误码。  异常处理 阿里巴巴《Java 开发手册（嵩山版）》 中有关异常处理给出了以下几点指导：
 异常设计的初衷是解决程序运行中的各种意外情况，而不是做流程或条件控制，且异常的处理效率比条件判断方式要低很多。 非受检异常如 RuntimeException、NullPointerException 等不应该通过 catch 的方式来处理，而是自行使用条件判断。 尽可能 区分异常类型，再做对应的异常处理。定义异常时区分 unckecked / checked 异常，避免直接抛出 new RuntimeException() 或是 Exception / Throwable，应使用 有业务含义 的自定义异常。 如果不想处理异常，可以将该异常抛出给它的调用者。最外层的业务使用者，必须处理异常，将其 转化 为用户可以理解的内容。在事务场景中，应注意在 catch 后 手动回滚 事务。 finally 块必须对资源对象、流对象进行关闭，推荐使用 try-with-resources 方式。在 finally 中禁止使用 return，finally 中的 return 会无情地屏蔽掉 try 中的 return 语句。 方法的返回值可以为 null，不强制返回空集合，或者空对象等，必须添加 注释充分说明什么情况下会返回 null 值。必须考虑到远程调用失败、 序列化失败、运行时异常等场景返回 null 的情况。 防止 NullPointerException 是程序员的基本修养，注意 NPE 产生的场景：  返回类型为基本数据类型， return 包装数据类型的对象时，自动拆箱有可能产生 NPE。 反例： public int f() { return Integer 对象}， 如果为 null，自动解箱抛 NPE。 数据库的查询结果可能为 null。 集合里的元素即使 isNotEmpty，取出的数据元素也可能为 null。 远程调用返回对象时，一律要求进行空指针判断，防止 NPE。 对于 Session 中获取的数据，建议进行 NPE 检查，避免空指针。 级联调用 obj.</description>
    </item>
    
    <item>
      <title>Database：InnoDB 存储引擎</title>
      <link>https://hoffmanzheng.github.io/2021/database-innodb/</link>
      <pubDate>Thu, 07 Jan 2021 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2021/database-innodb/</guid>
      <description>在之前的博客 Database：MySQL 数据库 中笔者已经介绍了自己对于关系型数据库 MySQL 的些许认识，但终觉不够深刻，本篇将结合 《MySQL技术内幕：InnoDB存储引擎》 讲解作为 MySQL 企业级数据库应用的第一存储引擎 InnoDB 的 核心实现和工作机制，主要内容有：缓冲池、后台线程工作机制、日志文件、锁、事务等。
MySQL 存储引擎 MySQL 数据库区别于其他数据库的最重要的一个特点就是其 插件式的表存储引擎（Pluggable Storage Engines），其提供了一系列标准的管理和服务支持，如 SQL 分析器和优化器等，这些标准与存储引擎本身无关，而存储引擎是底层物理结构的实现，每个存储引擎开发者可以按照自己的意愿来进行开发。 MySQL 数据库的体系结构如下图：
需要注意的是，存储引擎是 基于表的，而不是数据库。每个存储引擎都有各自的特点，开发者应该根据具体的应用选择适合的存储引擎，以下是一些存储引擎的简单介绍：
InnoDB 支持事务，行锁，外键，使用 MVCC 获得高并发性，实现了 SQL 的 4 种隔离级别，默认为 REPEATABLE，使用一种被称为 next-key locking 的策略来避免幻读（phantom）现象的产生，聚集索引，按主键顺序，从 MySQL 5.5.8 开始成为 MySQL 默认的存储引擎，众多互联网公司的成功应用已经证明了 InnoDB 存储引擎的高可用性、高性能以及高可扩展性。
MyISAM 不支持事务，表锁，支持全文索引，在 5.5.8 之前是默认的存储引擎，只缓存索引文件，不缓冲数据文件。
NDB 集群 存储引擎，数据全部放在内存中，主键查找速度极快，通过添加 NDB 数据存储节点（Data Node）可以线性地提高数据库性能；有一个问题值得注意，那就是 NDB 存储引擎的连接操作 JOIN 是在 MySQL 数据库层完成的，而不是在存储引擎层完成的。这意味着，复杂的连接操作需要巨大的网络开销，因此关联查询速度很慢。
Memory 数据存放于内存，数据库重启或者发生崩溃，表中的数据都将消失，使用了 哈希索引，只支持表锁，并发性能较差；MySQL 使用 Memory 存储引擎作为 临时表 来存放查询的中间结果集。
Archive 只支持 INSERT SELECT 操作，支持索引，压缩比例 1：10，非常 适合存储归档数据，如日志信息。使用行锁来实现高并发的插入操作，但并不是事务安全的引擎。</description>
    </item>
    
    <item>
      <title>Git 进阶与 GitHub 协作详解</title>
      <link>https://hoffmanzheng.github.io/2020/advanced-git/</link>
      <pubDate>Mon, 28 Dec 2020 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/advanced-git/</guid>
      <description>在 Git 与 GitHub 使用指北 中笔者已经介绍了 Git 及 GitHub 的基本操作，但对其原理不明所以，本篇将在之前的基础上结合 Git Reference Manual 介绍一些 Git 底层原理和高阶操作，以及在 GitHub 协作的流程。
Git 进阶 仓库、提交、分支的本质 Repository Git 仓库的本质其实就是一个可以 追溯所有历史 的文件夹，历史的最小单位是仓库在某个时刻的状态（快照）。每一次对仓库的 commit 提交都将产生一个 commitID， 它代表着整个仓库所有的文件和文件夹在某个时刻的状态 / 副本 / 代码快照，所以仓库的本质即是所有这些快照的集合。
可以通过 git log 来查看仓库历史上的状态，然后使用 git checkout &amp;lt;commitID&amp;gt; 来使仓库恢复到某个状态。在 GitHub 网站上可以使用 https://github.com/&amp;lt;userName&amp;gt;/&amp;lt;repositoryName&amp;gt;/tree/&amp;lt;commitID/tag/branch&amp;gt; 看到这个仓库在某个时刻的状态。
以下几种方式都可以标识仓库的状态：
 提交的 commitID，是一个十六进制字符串的 SHA-1 分支名 branch，指向分支最新一次的提交 HEAD，指向当前分支的头 标签 tag，是针对某个仓库状态打的标签，git tag v1.0   相关阅读：GeeksforGeeks：What is a GIT Repository?
 Commit commit 提交是指将仓库从一个状态转移到另外一个状态时发生的变化，它产生的 commit 对象包括：</description>
    </item>
    
    <item>
      <title>Database：高性能 MySQL - 优化查询</title>
      <link>https://hoffmanzheng.github.io/2020/database-optimize-sql/</link>
      <pubDate>Tue, 22 Dec 2020 13:29:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/database-optimize-sql/</guid>
      <description>一个 MySQL 的查询任务，可以看作是一系列子任务，每个子任务都会消耗一定的时间，包括：网络、CPU 计算、生成统计信息和执行计划、锁等待等。如果要优化查询，实际上要优化其子任务，消除其中的一些子任务，减少子任务的执行次数，让子任务运行得更快。因此，了解 查询的生命周期、清楚查询的时间消耗情况对于优化查询有很大的意义。
在 Database：高性能 MySQL - 索引 篇笔者已经讲述了索引对良好的性能有着重要的影响，但如果查询写的很糟糕，即使库表结果再合理、索引再合适，也无法实现高性能。本篇基于 MySQL 5.5 版本，结合 《高性能 MySQL》 第六章 查询性能优化 的内容讲解 MySQL 如何真正地执行查询，查询高效和低效的原因何在，以及该如何对各种类型的查询，比如子查询、关联查询、排序、分组、分页等，进行合理的设计。
查询执行的基础 MySQL 客户端/服务器通信协议 一般来说不需要去理解 MySQL 通信协议的内部实现细节，只需要大致理解通信协议是如何工作的。MySQL 客户端和服务器之间的通信协议是 &amp;ldquo;半双工&amp;rdquo; 的，这意味着在任何一个时刻，要么是由服务器向客户端发送数据，要么是由客户端向服务器发送数据，这两个动作不能同时发生，无法也无须将一个消息切成小块独立来发送。
这种协议让 MySQL 通信简单快速，但也给了 MySQL 一些限制，比如：
  无法进行 流量控制，服务器必须接收客户端传来的完整查询消息才能响应，当查询语句过长超过 max_allowed_packet 时，服务器会拒绝接收并抛出错误。
  客户端必须完整地接收整个返回结果，而不能简单地只取前面几条结果，然后让服务器停止发送数据。这也是在必要的时候一定要在查询中加上 LIMIT 限制的原因。
  MySQL 通常需要等所有数据都发送给客户端后才能 释放这条查询所占用的资源，如果查询返回了一个很大的结果集，库函数会花很多时间和内存来存储所有的结果集，给服务器造成一定的压力。
  查询执行流程 MySQL 执行一个查询的过程，大体上可分为服务器层和存储引擎层两部分：
Server 层    阶段 职责     连接器 TCP 握手后服务器端验证登录用户身份   查询缓存 先检查查询缓存，如果命中则立刻返回存储在缓存中的结果   分析器 根据语法规则判断输入的 SQL 语句是否满足语法规范   优化器 选择并生成最优的执行计划   执行器 调用存储引擎的 API 执行查询    存储引擎层 负责数据的存储和提取，MySQL 插件式的存储引擎架构支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.</description>
    </item>
    
    <item>
      <title>Database：高性能 MySQL - 索引</title>
      <link>https://hoffmanzheng.github.io/2020/database-index/</link>
      <pubDate>Thu, 10 Dec 2020 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/database-index/</guid>
      <description>在之前的博客 Database：MySQL 数据库 我已经介绍了自己对 MySQL 的一些基本认识，包括它的存储引擎、数据存储结构、索引及事务等，本篇及之后的一篇将着眼于 MySQL 的性能深入探究。
索引是存储引擎用于快速找到记录的一种数据结构，它对良好的性能非常关键，它能让 MySQL 以最高效、扫描行数最少的方式找到需要的记录。本篇将结合 《高性能 MySQL》 第五章 创建高性能的索引 的内容深入分析，如何使用索引来提高 MySQL 数据库的查询性能。
本篇使用和书本相同的 MySQL 5.5 版本，使用 官方提供的测试数据库 作为示例，通过 MySQL Workbench 导入 dump 数据。
索引的类型 B-Tree 索引 在 Database：MySQL 数据库 我已经介绍过 B-Tree 索引了，这里谈下一个面试常问的问题：为什么 MySQL 的索引要使用 B+ 树而不是其他的树形结构，比如 B 树？
 B 树是一颗多叉树，相比于二叉树在相等数据量的情况下，树的高度更低，可以减少查询时的 I/O 次数。 B+ 树相比 B 树，只有叶子节点存放数据，非叶子节点只存储索引，这样就能在一张 16kb 的非叶子节点数据页中 存储更多的指针，降低树的高度，减少查询 I/O 次数，提高查询性能。 计算机层面，一次 I/O 就是磁盘的 寻道、寻点、拷贝到内存 三步操作。寻道是磁臂移动到指定磁道所需要的时间，一般在 5ms 以下；寻点是从磁道中找到数据存在的那个点，平均为半圈时间，在一个 7200 转/min 的磁盘，大概是 60,000 / 7200 / 2 = 4.</description>
    </item>
    
    <item>
      <title>JVM：体系结构与内存管理</title>
      <link>https://hoffmanzheng.github.io/2020/jvm-architecture-memory/</link>
      <pubDate>Fri, 06 Nov 2020 13:37:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/jvm-architecture-memory/</guid>
      <description>在之前的博客 Javac 编译原理与 class 文件结构 中，我有提及 Javac 编译器将 Java 源码编译成了机器可以接受的指令，解决了高级语言与底层硬件架构的耦合（现在的操作系统几乎完全向用户屏蔽了硬件，也就可以说编译器解决了高级语言与不同操作系统之间的耦合）。
JVM 屏蔽了各个计算机平台相关的软件或者硬件之间的差异，使 Java 代码可以 全平台运行。本篇以 《深入分析 Java Web 技术内幕》 第七章 JVM 体系结构与工作方式 及第八章 JVM 内存管理 的内容为参考，讲解 JVM 的基本结构、工作方式、内存分配策略及垃圾回收策略等。
JVM 体系结构 计算机与 Java 虚拟机 在了解 JVM 这台虚拟计算机之前，我们先看看一台真实的计算机的体系结构：
   计算机组成部分 功能     指令集 计算机所能识别的机器语言的命令集合   计算单元 能识别并控制指令执行的功能模块   寄存器 操作数寄存器、控制寄存器、变址寄存器等   存储单元 存储操作数和保存操作结构的单元，内存和磁盘等   寻址方式 地址位数、最小最大地址范围、地址的运行规则等    指令集 是在 CPU 中用来计算和控制计算机系统的一套指令的集合，在 CPU 设计时规定的一系列与硬件电路相配合的指令系统。可以说指令集是可以直接被机器识别的机器码，必须以二进制格式存在于计算机中，而 汇编语言 是为了让人能够更容易地记住机器指令而使用的助记符，每一条汇编指令都可以直接翻译成一个机器指令。</description>
    </item>
    
    <item>
      <title>深入分析 ClassLoader 工作机制</title>
      <link>https://hoffmanzheng.github.io/2020/java-classloader/</link>
      <pubDate>Tue, 22 Sep 2020 09:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/java-classloader/</guid>
      <description>Java 是个强类型的编程语言，一个变量的类型在编译时就已经决定了，就是最初声明它的类型， 如果想把它当成另一个类型来使用，需要先经过显式的类型转换，转换时可能会因为类型不符而抛出 ClassCastException。
本篇以 《深入分析 Java Web 技术内幕》 第六章 深入分析 ClassLoader 工作机制 的内容为参考，讲解 Java 中的类型，类加载机制，类加载错误分析 等。
Java 中的类型 如开篇所说，一个 Java 对象的类型在声明的时候就被确定了，但 Java 是面对对象的语言，有丰富的接口和抽象类，一个对象被传来传去的时候，可能就丢失了它的一些类型信息，但 Java 也像 C++ 那样是拥有 RTTI (Run-Time Type Identification) 运行时类型识别 特性的语言。在任何时刻，任何一个对象都清楚地知道自己的具体类型（可以通过反射获取）。
不知道大家有没有想过，Java 中的对象是如何被创造出来的，创造时是否又遵循了一个怎样的规则。其实 Java 中的对象都是根据各自的说明书构建出来的，这个说明书信息就是在 Javac 编译原理与 class 文件结构 中生成的类的 class 字节码文件之中，这些字节码文件又被存储在永久代 (Permenent Generation Java 7 之前) / 元空间 (MetaSpace Java 8 之后) 之中。
当需要创建一个对象时，就会将这个创建任务委托给类加载器来完成，类加载器会找到指定的 class 字节码文件，根据说明书来装配出一个需要的对象。因此任何一个 Java 对象，在运行时都清楚的知道自己是由哪个类的字节码装配出来的，都可以通过 getClass() / instanceof 来获取自己的具体类型。
类加载机制 JVM 类加载机制分为五个部分：加载、验证、准备、解析、初始化，如下所示：
   类加载阶段 作用     加载 生成 Class 对象，作为方法区这个类的各种数据入口   验证 确保 Class 文件的字节流中包含的信息符合当前虚拟机的要求   准备 为类变量分配内存空间，并设置变量初始值，非 finanl 是0，final 会赋值   解析 虚拟机将常量池中的符号引用替换为直接引用的过程   初始化 执行类构造器方法（静态语句块）    ClassLoader 类加载器 类加载器 ClassLoader 在 JDK 源码中的 rt.</description>
    </item>
    
    <item>
      <title>Javac 编译原理与 class 文件结构</title>
      <link>https://hoffmanzheng.github.io/2020/java-compile/</link>
      <pubDate>Sat, 05 Sep 2020 09:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/java-compile/</guid>
      <description>JVM 让 Java 成为了一次编译，到处运行，具有平台无关性的高级语言。要让 Java 代码跑在 JVM 中少不了 Javac 编译器，它把人类能理解的 Java 源代码语言翻译成 JVM 容易理解的字节码（将 .java 文件转换成 .class 文件）。某种意义上来说，Javac 编译器的存在使 Java 语言向开发者屏蔽了很多与机器相关的细节，JVM 使 Java 语言的执行和平台无关，这才成就了 Java 的繁荣。
本篇以 《深入分析 Java Web 技术内幕》 第四章 Javac 编译原理 及第五章 深入 class 文件结构 的内容为参考，讲解 Javac 编译器的基本结构，Javac 的工作原理，class 文件结构等。
Javac 编译器的基本结构 Javac 编译器的作用就是将符合 Java 语言规范的源代码转化成符合 Java 虚拟机规范的 Java 字节码，是从一个语言规范到另一个语言规范的转化，这大概需要以下几个步骤：
   编译过程 步骤     词法分析过程 识别源代码中的语法关键词，形成 Token 流   语法分析过程 检查关键词组合是否符合 Java 语言规范，形成一个抽象语法树   语义分析过程 把一些难懂的、复杂的语法转化成更加简单的语法，形成一个注解过后的抽象语法树   字节码生成 根据注解过后的抽象语法树生成字节码    词法分析过程 在 Javac 编译一个类之前，会先一个字节一个字节地读取源代码，找出其中的语法关键词，如 if、else、for、while 等，最后形成一些规范化的 Token 流，就像在人类语言中，分辨一句话中的动词、名词、标点符号等。</description>
    </item>
    
    <item>
      <title>深入分析 Java Web 中的中文编码问题</title>
      <link>https://hoffmanzheng.github.io/2020/java-encode/</link>
      <pubDate>Sat, 29 Aug 2020 09:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/java-encode/</guid>
      <description>作为非英语国家程序员，编码问题是我们一直都绕不过去的一道坎。
本篇以 《深入分析 Java Web 技术内幕》 第三章 深入分析 Java Web 中的中文编码问题 的内容为参考，讲解常见的编码格式、Java 中的编解码、Java Web 中的编解码，及常见乱码问题分析等。
计算机中存储信息的最小单元是 1 个字节，即 8 bits，所以能表示的字符范围是 0~255 个，而我们人类的语言太多，表示这些语言的符号太多，因而必须要经过一些翻译工作，才能让计算机理解我们的语言。这个翻译工作就是从 char 到 byte 的编码过程。
常见的编码格式 ASCⅡ 码 使用一个字节的低 7 位表示，范围为 0~127 共 128 个，包括了英文大小写字母，数字及常用的数学符号。0~31 是控制字符如换行、回车、空字符等，32~126 是打印字符，127 为删除。
IOS-8859-1 ASCⅡ 码的 128 个字符显然是不够用的，ISO 组织在 ASCⅡ 码基础上扩展出 ISO-8859-1 至 ISO-8859-15，其中 ISO-8859-1 涵盖了大多数西欧语言字符，应用最广泛。ISO-8859-1 仍然是 单字节编码，总共能表示 256 个字符。
GB 2312 《信息交换用汉字编码字符集》，双字节编码，范围为 A1~F7，包含 682 个符号和 6763 个汉字。
GBK 《汉字内码扩展规范》扩展了 GB2312，加入更多的汉字，编码范围是 8140~FEFE，能表示 21003 个汉字，兼容 GB 2312。也就是说用 GB 2312 编码的汉字可以用 GBK 来解码且不会用乱码。</description>
    </item>
    
    <item>
      <title>深入分析 Java I/O 的工作机制</title>
      <link>https://hoffmanzheng.github.io/2020/java-io/</link>
      <pubDate>Mon, 17 Aug 2020 09:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/java-io/</guid>
      <description>I/O 是任何编程语言都无法回避的问题，它是人机交互中机器获取和交换信息的主要渠道，可以说大部分 Web 应用系统的瓶颈都是 I/O 瓶颈。
本篇以 《深入分析 Java Web 技术内幕》 第二章 深入分析 Java I/O 的工作机制 的内容为参考，讲解 Java I/O 类库、磁盘 I/O、网络 I/O、NIO 工作机制等。
Java I/O 类库的基本架构 基于字节的 I/O 操作接口 无论是磁盘还是网络传输，最小的存储单元都是字节，而不是字符，所以 I/O 操作的都是字节而不是字符，Java 中基于字节的 I/O 操作接口输入和输出分别是 InputStream 和 OutputStream，其类层次关系如下图所示。
需要明确的是，字节流从哪里读或是写入到哪里，操作数据的方式是可以组合使用的，如：
OutputStream outputStream = new BufferedOutputStream(new FileOutputStream(new File(&amp;#34;pathName&amp;#34;))); 基于字符的 I/O 操作接口 虽然 I/O 操作的都是字节，但我们在程序中通常都是操作字符，为了方便 JDK 也提供了一个直接写字符的 I/O 接口 Reader 和 Writer，这样我们就可以直接将字符写入到文件或者网络流去。
例如写字符的操作接口为 void write(char[] cbuf, int off, int len)
字节与字符的转化接口 字符在写入文件持久化或者网络传输之前，都需要先经过编码转换，下图中 InputStreamReader 就是从字节到字符的转化桥梁，在初始化时需要指定编码字符集，否则会采用操作系统默认的字符集，很可能出现乱码问题。具体的编码解码过程可以查看：深入分析 Java Web 中的中文编码问题</description>
    </item>
    
    <item>
      <title>深入 Web 请求过程</title>
      <link>https://hoffmanzheng.github.io/2020/dns-cdn/</link>
      <pubDate>Sun, 26 Jul 2020 09:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/dns-cdn/</guid>
      <description>由于之前找工作，刚来上海挺多事，些久没写博客；至此打算新开一个 “学习录” 系列（以读书笔记和实战心得为主），记录自己 Java 学习路上的收获，共勉。
以 《深入分析 Java Web 技术内幕》 第一章 深入 Web 请求过程的内容为参考，此篇讲解游览器缓存、DNS 域名解析的过程和 CDN 工作机制。
游览器缓存 缓存可以减少游览器向服务器请求资源的次数，减少网络延时，加快页面响应速度，减少服务器压力。下图中 size 不为 0 的请求就是没有使用缓存。
Memory Cache 会将资源暂时缓存到内存中，在关闭游览器后会释放掉这部分内存空间。受限于计算机内存的大小，当内存使用率高的时候，资源大概率会被缓存到 Disk Cache，它可以长时效的在硬盘中缓存资源。
Cache-Control / Pragma 我们在游览一个页面时发现有异常，通常考虑的就是是不是游览器做的缓存，这个时候可以按 Ctrl + F5 来重新请求到没有缓存的页面。这个组合键会直接向目标 URL 发送请求，而不会使用游览器缓存的数据；它会在 HTTP 的请求头中增加一些请求头，告诉服务器我们要获取最新的数据而不是缓存（以此也可以跳过前端部署的缓存服务器）。
 对 HTTP 请求头不太熟悉的同学可以先参考下我的计网学习笔记：Net：计算机网络读书笔记。
 使用 Ctrl + F5 组合键后在 HTTP 请求头中增加了两项 Pragma:no-cache 和 Cache-Control:no-cache，其字段可选值如下表所示：
   可选值 说明     Private 所有内容都将被缓存，在响应头中设置   Private 内容只缓存到私有缓存中，在响应头中设置   no-cache 所有内容都不会被缓存，在请求头和响应头中设置   no-store 所有内容都不会被缓存到缓存或 Internet 临时文件中，在响应头中设置   must-revalidation/proxy-revalidation 如果设置的内容失效，请求必须发送到服务器 / 代理以进行重新验证，在请求头中设置   max-age=xxx 缓存的内容将在 xxx 秒后失效，这个选项只在 HTTP 1.</description>
    </item>
    
    <item>
      <title>Java：程序的部署和 Nginx 负载均衡</title>
      <link>https://hoffmanzheng.github.io/2020/deploy/</link>
      <pubDate>Tue, 21 Apr 2020 11:30:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/deploy/</guid>
      <description>本篇介绍 Java 程序部署的三种方式：exec 插件、jar 包、Docker 方式部署，以及使用 Nginx 实现简单的负载均衡。
Java 程序的部署 Maven exec 插件部署  导入 Maven 的 exec 插件：Maven Repository：exec-maven-plugin，然后在 pom.xml 中进行配置，使之可以调用外部命令执行 Java 程序并自动加载依赖的 classpath 路径：  &amp;lt;plugin&amp;gt; &amp;lt;groupId&amp;gt;org.codehaus.mojo&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;exec-maven-plugin&amp;lt;/artifactId&amp;gt; &amp;lt;version&amp;gt;1.6.0&amp;lt;/version&amp;gt; &amp;lt;executions&amp;gt; &amp;lt;execution&amp;gt; &amp;lt;id&amp;gt;run&amp;lt;/id&amp;gt; &amp;lt;goals&amp;gt; &amp;lt;goal&amp;gt;exec&amp;lt;/goal&amp;gt; &amp;lt;/goals&amp;gt; &amp;lt;configuration&amp;gt; &amp;lt;executable&amp;gt;java&amp;lt;/executable&amp;gt; &amp;lt;arguments&amp;gt; &amp;lt;argument&amp;gt;-classpath&amp;lt;/argument&amp;gt; &amp;lt;!-- automatically creates the classpath using all project dependencies, also adding the project build directory --&amp;gt; &amp;lt;classpath/&amp;gt; &amp;lt;argument&amp;gt;com.github.hoffmanzheng.springboot.Application&amp;lt;/argument&amp;gt; &amp;lt;/arguments&amp;gt; &amp;lt;/configuration&amp;gt; &amp;lt;/execution&amp;gt; &amp;lt;/executions&amp;gt; &amp;lt;/plugin&amp;gt; mvn exec:exec@[executionID] 即可完成程序的部署；-X 参数可以用于排查部署时出现的问题，-DskipTests 可以跳过测试。 windosw下（需使用系统 cmd） netstat -ano | findstr &amp;quot;8080&amp;quot; 可以查看当前端口被占用的情况，tasklist |findstr &amp;quot;进程id号&amp;quot; 查找对应的进程名称，然后 taskkill /f /t /im &amp;quot;进程id或者进程名称&amp;quot; 杀掉当前占用端口的进程  部署效果图：</description>
    </item>
    
    <item>
      <title>Java：线程池原理、源码分析</title>
      <link>https://hoffmanzheng.github.io/2020/java-threadpool/</link>
      <pubDate>Fri, 27 Mar 2020 10:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/java-threadpool/</guid>
      <description>本篇为 Java：初识多线程、原理及实现 的续篇，介绍 Java 中的线程池，主要内容有：进程与线程、线程池化的意义、Executors 工具类、线程池工作流程、线程复用原理等。
为什么需要线程池 进程与线程 起源 进程 是在批处理操作系统的基础上，为进一步提高计算机效率，改善操作系统串行的运行方式的产物。进程的出现改变了内存中始终只有一个程序运行的事实，进程是在内存中独享一片内存空间的程序，各个进程之间互不干扰。
CPU 采用 时间片轮转 的方式运行进程，使用上下文切换的方式让操作系统的并发成为可能。虽然并发从宏观上看有多个任务在执行，但对于单核 CPU 来说，任意时刻都只有一个任务在占用 CPU 资源。
 上下文指某一时刻 CPU 寄存器和程序计数器的内容，通过在内存中保存 / 读取来完成其切换。上下⽂切换通常是计算密集型的，意味着此操作会消耗⼤量的 CPU 时间，故线程也不是越多越好。如何减少系统中上下⽂切换次数，是提升多线程性能的⼀个重点课题。
 如果说进程让操作系统的并发性成为了可能，那么 线程 就让进程的内部并发成为了可能。每个线程执行进程中的一个子任务，使得杀毒软件一遍检测用户电脑一遍清理垃圾成为可能。
进程和线程的区别  进程间的通信比较复杂，而线程间的通信比较简单。线程相比进程更为轻量级，多线程并发相比多进程开销更小。 进程和线程本质的区别是 是否单独占有内存地址空间及其他的系统资源（比如 I/O）：进程间存在内存隔离，而线程共享所属进程占有的内存地址空间和隔离，数据共享简单，但是同步复杂。 进程是操作系统进行资源分配的基本单位，而线程是操作系统进行调度的基本单位。一个进程出现问题不会影响其他进程；而一个线程崩溃可能影响整个程序的稳定性。  Java 线程与操作系统内核线程 用户级线程与内核级线程 推荐阅读：用户级线程和内核级线程，你分清楚了吗？
 用户级线程 ULT：由应用程序实现和管理（创建、同步、调度等），线程阻塞则整个进程阻塞。对操作系统来说，用户级线程具有不可见性、透明性，ULT 下 CPU 的调度还是以进程为单位。 内核级线程 KLT：需通过 系统调用 创建，由系统内核管理，可实现多核 CPU 并行处理。线程阻塞不会影响同进程内其他线程的运行。  线程池的意义  JVM 运行在用户态，通过调用系统库来创建内核线程，由 CPU 来完成线程的调度；但是从用户态到内核态的权限提升和状态切换需要相当的 系统开销，频繁的创建和销毁线程将不利于程序性能的提升。 为此，将线程池化管理，对线程进行统一分配、调优和监控，避免频繁的线程创建，减少状态切换带来的资源消耗，重用线程 就是使用线程池的意义。 线程池比较适合处理数量庞大，但是处理时间较短的任务。如果某个任务耗时过长，会导致池内任务堆积。  线程池原理 ThreadPoolExecutor 的构造器参数 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&amp;lt;Runnable&amp;gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler)  corePoolSize：核⼼线程数，在没有任务执行时线程池的大小 maximumPoolSize：池内最大线程数，在工作队列满了的情况下会创建出超过非核心的线程   最大线程数 = 核心线程 + 非核心线程。非核心线程如果长时间闲置，就会被销毁。</description>
    </item>
    
    <item>
      <title>Database：MySQL 数据库</title>
      <link>https://hoffmanzheng.github.io/2020/database-mysql/</link>
      <pubDate>Wed, 04 Mar 2020 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/database-mysql/</guid>
      <description>本篇介绍 MySQL 数据库，主要内容有：MySQL 常见的两种存储引擎（InnoDB 与 MyISAM）、数据库存储结构与索引原理以及数据库事务隔离级别、读写锁等。
存储引擎 MyISAM 与 InnoDB 区别：   InnoDB 支持事务，MyISAM 不支持事务。这是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；
  InnoDB 支持外键，而 MyISAM 不支持。对一个包含外键的 InnoDB 表转为 MYISAM 会失败；（主键是能确定一条记录的唯一标识，外键用于与另一张表的关联）
  InnoDB 是聚集索引，MyISAM 是 非聚集索引（堆表）。
 聚集索引的文件存放在主键索引的叶子节点上，因此 InnoDB 必须要有主键，通过主键索引效率很高。但是辅助索引需要两次查询（回表），先查询到主键，然后再通过主键查询到数据。因此，主键不应该过大，因为主键太大，其他索引也都会很大。 聚集索引的顺序就是数据的物理存储顺序，所以 insert 和 update 操作可能会导致数据重排，而导致性能下降。 而 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针。主键索引和辅助索引是独立的。    InnoDB 不保存表的具体行数，执行 select count(*) from table 时需要全表扫描。而MyISAM 用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快；（MyISAM 查询效率更高，且支持全文索引）
  InnoDB 最小的锁粒度是 行锁，MyISAM 最小的锁粒度是表锁。一个更新语句会锁住整张表，导致其他查询和更新都会被阻塞，因此并发访问受限。这也是 MySQL 将默认存储引擎从 MyISAM 变成 InnoDB 的重要原因之一；</description>
    </item>
    
    <item>
      <title>Net：计算机网络读书笔记</title>
      <link>https://hoffmanzheng.github.io/2020/net-http-tcp/</link>
      <pubDate>Thu, 27 Feb 2020 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/net-http-tcp/</guid>
      <description>本篇为 《计算机网络自顶向下方法》 的读书笔记，主要介绍：网络分层模型、HTTP 协议、非持续连接和持续连接、报文格式、cookie 与 session、 FTP 协议、HTTPS 协议、TCP 协议、流量控制、UDP 协议 等。
网络协议分层模型 ISO 提出的计算机网络 OSI（Open System Interconnection Reference Model） 七层模型：
TCP / IP 分层模型：
分层体系的优点：HTTP 协议不用担心数据丢失，也 不关注 TCP 从网络的数据丢失和乱序故障中恢复的细节。那是 TCP 以及协议栈较低层协议的工作。
应用层 现代网络应用有两种主流体系结构：客户 - 服务器体系结构 或 对等（P2P）体系结构。网络应用通过 socket 软件接口向网络发送报文 message 和从网络接收报文来实现在 不同端系统上的进程间的通信。
应用层协议定义了：
 换的报文类型，例如请求报文和响应报文 。 各种报文类型的语法，如报文中的各个字段及这些字段是如何描述的 。 字段的语义，即这些字段中包含的信息的含义 。 一个进程何时以及如何发送报文，对报文进行响应的规则。  HTTP 协议 Web 的应用层协议是超文本传输协议 (HyperText Transfer Protocol , HTTP) ，客户端和服务器端通过交换 HTTP 报文进行会话，HTTP 定义了这些报文的结构以及客户和服务器进行报文交换的方式。
HTTP 定义了 Web 客户向 Web 服务器请求 Web 页面的方式，以及服务器向客户传送 Web 页面的方式。HTTP 使用 TCP 作为它的支撑运输协议，TCP 为 HTTP 提供可靠数据传输服务。</description>
    </item>
    
    <item>
      <title>Web：浅析 URL</title>
      <link>https://hoffmanzheng.github.io/2020/net-url/</link>
      <pubDate>Sun, 09 Feb 2020 09:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/net-url/</guid>
      <description>1990 年英国计算机科学家蒂姆·伯纳斯-李（Tim Berners-Lee）发明了万维网，并解决了其中三项关键技术： URL + HTML + HTTP。本篇讲述其中的一项，全球网络资源唯一认证的系统：URL 的基本知识。
IP 与端口 1. IP 和端口的作用  IP（Internet Protocal）是定位互联网中一台设备的协议，它规定了如何封装数据报文，以跟互联网中的其他设备交流。只要你在互联网中，你就至少有一个独特的 IP。 端口（Port）是用来定位互联网中一台设备中的不同服务的。  2. 内网与外网 形象点描述，外网就好比我家的地址，内网就类似我在我家的位置。外网是实现互联网中设备间互相通信的基础，内网和外网之间使用路由器进行中转。
2.1 外网 IP 当我们租用电信宽带，安装猫和路由器后，便拥有了自己的外网 IP（由运营商分配）。需要注意的是，你的所有设备都共享一个外网 IP；如果重启路由器，外网 IP 将会被重新分配。
可以通过 ipconfig 或访问 IP 138.com 来查看自己的外网 IP。
2.2 内网 IP 内网 IP 一般以 192.168.x.x 形式出现，内网中的设备可以互相访问，但想访问外网需要通过路由器中转；同样地，外网设备要把数据内容送到内网也必须通过路由器。
路由器可以说是内网和外网这两个隔绝空间之间的唯一连通点，故也被称为网关。
2.3 几个特殊的 IP localhost 表示本地
127.0.0.1 表示自己
0.0.0.0 不表示任何设备
3. 端口的约定 当数据内容通过外网及内网 IP 唯一定位到用户设备后，需要通过端口传输给指定的服务。常用的服务有：端口列表
 HTTP 服务：80 端口 HTTPS 服务：443 端口 FTP 服务：21 端口  关于端口有几个约定：</description>
    </item>
    
    <item>
      <title>Web：HTML 常用标签</title>
      <link>https://hoffmanzheng.github.io/2020/net-html/</link>
      <pubDate>Sat, 08 Feb 2020 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/net-html/</guid>
      <description>HTML（Hyper Text Markup Language）超文本标记语言，是构建网站的基石。游览器通过解析 HTML 来将万维网中传输的 字节流 渲染成丰富多彩的可视化网页。
由于我不是写前端的，就用在线 Web 调试工具 饥人谷 JsBin 和 代码沙盒 来进行 HTML 的编辑。更多参考资料：MDN HTML 文档。
HTML 章节与内容标签 1. HTML 起手式 HTML 代码由许许多多不同的标签（tag）构成。下图为 HTML 的一个常规模版：
 &amp;lt;head&amp;gt; 里面一般放一些看不见的元素，如编码方式、全文样式 &amp;lt;style&amp;gt; 、标题、JS等 &amp;lt;body&amp;gt; 里面写网页的具体内容 模版中的内容只需要改 title 和语言，其他暂时都不变。 有个输入标签的快捷键，打出标签单词后按键盘上的 Tab 键就可以快速补全代码了。  2. HTML 章节标签 章节标签用于划分网页 / 文章的层级，使页面结构清晰，也便于添加 CSS 样式
 标题：&amp;lt;h1~h6&amp;gt; 字体从大到小，h1 一个页面最多一个，不能为了调整字体大小而使用 章节：&amp;lt;section&amp;gt; 开始了一个新的章节，里面一般用 h2，h3；章节里面可以再套章节 文章：&amp;lt;article&amp;gt; 段落：&amp;lt;p&amp;gt; 头部：&amp;lt;header&amp;gt; 放置顶的广告 脚部：&amp;lt;footer&amp;gt; 最下面的版权声明等，&amp;amp;copy;打出版权的符号 主要内容：&amp;lt;main&amp;gt; 里面是标题+章节 旁支内容：&amp;lt;aside&amp;gt; 可以写导航，或在 main 的下面写个参考资料 划分：&amp;lt;div&amp;gt; 用于划分页面结构，使结构更加清晰  3.</description>
    </item>
    
    <item>
      <title>Java：HashMap 源码解读</title>
      <link>https://hoffmanzheng.github.io/2020/java-hashmap/</link>
      <pubDate>Tue, 28 Jan 2020 14:11:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/java-hashmap/</guid>
      <description>本篇基于哈希表的源码详解哈希表相关的各种问题，包括底层实现、扩容机制、get / put 过程、JDK 1.8 的改进、并发问题及 key 问题，并对源码文档进行翻译。
HashMap 的实现原理 1. 哈希表底层实现原理 哈希表是一个使用数组与链表（红黑树）实现的键值对集合。哈希桶由 Node 数组构成，键值对用实现了 Entry&amp;lt;K, V&amp;gt; 接口的内部类 Node 存储，它具有 next 指针，将同一个哈希桶中的键值对结构链表化；当桶中的键值对数量超过树化阈值 8 时，哈希桶会转变成红黑树结构。
transient Node&amp;lt;K,V&amp;gt;[] table; static class Node&amp;lt;K,V&amp;gt; implements Map.Entry&amp;lt;K,V&amp;gt; { final int hash; final K key; V value; Node&amp;lt;K,V&amp;gt; next; } 2. 为什么采用数组+链表的数据结构 数组的随机访问功能为 O(1) 的哈希表（get / put）操作提供了性能保障；链表用于解决哈希冲突，存放具有哈希冲突的元素；同时链表数据结构在增删元素的时候比较方便，不用像数组一样在扩容的时候 new 一个再复制。
为了改善链表不适合查找的问题，JDK 8 提供了将链表转换成适合查找的红黑树的功能。
3. 哈希冲突的解决办法  开放地址法： 链地址法： 再哈希法： 公共溢出区域法：  HashMap 扩容 1. HashMap 在什么条件下扩容 若当前哈希表实例为 null 或者 put 后实例的数据量 size 超过容量 * 装载因子，则会触发 resize() 方法，初始化 table 或是使哈希表容量翻倍。</description>
    </item>
    
    <item>
      <title>Java：多线程下的安全容器</title>
      <link>https://hoffmanzheng.github.io/2020/java-thread-safe-collection/</link>
      <pubDate>Thu, 16 Jan 2020 13:19:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/java-thread-safe-collection/</guid>
      <description>在我之前的博客 Java：初识多线程、原理及实现 提及，多线程下对数据的非原子性操作会造成数据错误，为此 JDK 也提供了一些线程安全的容器。本篇主要介绍 List 类的安全容器：Vector 和 CopyOnWriteArrayList，以及 Map 类的 HashTable 和 ConcurrentHashMap。从他们之前的区别，后者对前者的改进，具体的实现原理这几个角度进行分析。
List 类的安全容器 1. Vector 与 SynchronizedList 1.1 Vector Vector 类通过将所有的方法声明 synchronized 来保证数据的线程安全。但同步的确是整个 vector 实例，导致一个线程在访问实例时，其他线程都需要等待的尴尬情形，较大的同步开销完全不符合并发设计的初衷。此外，多线程下对 Verctor 的复合操作（如遍历+修改）仍会导致 并发修改异常。
public synchronized boolean add(E e); public synchronized boolean isEmpty(); public synchronized E get(int index); public synchronized void sort(Comparator&amp;lt;? super E&amp;gt; c); 1.2 SynchronizedList SynchronizedList 类和 vector 类似，只不过是在方法内进行同步锁：
public E get(int index) { synchronized (mutex) {return list.get(index);}} public E set(int index, E element) { synchronized (mutex) {return list.</description>
    </item>
    
    <item>
      <title>Java：初识多线程、原理及实现</title>
      <link>https://hoffmanzheng.github.io/2020/java-multi-thread/</link>
      <pubDate>Sun, 12 Jan 2020 14:49:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/java-multi-thread/</guid>
      <description>多线程原理 1. 为什么需要多线程 1.1 Java 代码的执行是同步阻塞模型 Java 代码在执行的时候，是从 main 代码块开始逐行执行，但当当前代码耗时过长时，下一行的代码就必须等待当前任务执行完毕，代码才能继续往下执行。
1.2 CPU的运算实在太快了 取主频为 3GHz CPU 为例，CPU 执行单个指令所需的时间约为 0.3ns；与之相对的，在内存中进行读取1MB大小文件所需时间大概为 250us，SSD随机读取耗时约为 1ms，HDD约为 20ms。（推荐阅读：我是一个CPU：这个世界慢！死！了！）
相比与内存，硬盘，网络传输，CPU 的运算实在是太快了，但是由于阻塞模型，如若当前代码执行的是较为耗时的 IO 操作，线程中的下一个任务就必须等待当前任务结束才能继续执行。使得单线程的代码执行非常没有效率，另外也浪费了 CPU 的运算性能。
2. Java 线程简介 2.1 多线程的方法栈 一般的 Java 程序都是从启动类的 main 函数入口开始执行，随着 main 函数的结束而停止. 这条执行路径就是 Java 程序的主线程。Java 虚拟机允许拥有同时运行多个线程，当新线程运行时，就会在栈中生成一个新的方法栈，新线程独享单独的执行流和局部变量，而静态变量则是被所有线程共享的。
2.2 多线程的性能 使用多线程就只有好处没有坏处吗？并不是，使用多线程是要付出代价的，如果没有耗时的任务，使用多线程，效率反而更低，因为CPU 在线程间的切换也需要耗费时间。引用知乎上看到的一句话：
 多线程在 CPU 密集型的作业下的确不能提高性能甚至更浪费时间，但是在 IO 密集型的作业下则可以提升性能（或者更准确点说叫平均响应时间）。
 由上得出的结论是，正确的使用多线程可以提高程序的运行效率。
3. 多线程问题的来源 3.1 多线程下的数据安全问题 多线程同时对一个共享的全局变量进行非原子操作将会引发严重的数据安全问题。
  原子操作可理解为不可分隔的操作，而非原子操作例如 i++ 则可以分解为 temp = i; temp = temp + 1; i = temp; 这样的取值、运算、赋值三个独立的操作。</description>
    </item>
    
    <item>
      <title>Java：Collection、Map 集合工具类</title>
      <link>https://hoffmanzheng.github.io/2020/java-collection/</link>
      <pubDate>Thu, 02 Jan 2020 16:11:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2020/java-collection/</guid>
      <description>本篇介绍 Java 中集合类框架的基础知识，包括 List，Set，Map。此外，关于使用频率最高的容器 HashMap 则会在另一篇博文 Java：HashMap 源码解读 中详细分析；关于这些集合类的线程安全问题，会在 Java：多线程下的安全容器 中进行讲述。
Collection 继承体系 1. 集合 Collection 介绍  为什么需要集合？  集合使 Java 可以处理多个同类型的对象（List / Set），亦或是多个键值对类型的数据（Map）。   集合的常用功能：  添加：add(Object obj)、addAll(Collection c)； 删除：clear()、remove(Object)、removeAll(Collection)； 判断包含：isEmpty()、contains(Object)、containsAll(Collection)；  contains 方法进行判定时，会调用 equals 方法，所以在用集合存储引用对象（非原生数据类型）时需要重写 equals 和 HashCode 方法。   遍历获取：Iteratoriterator()； 长度：size()； 交集：retainAll(Collection c)； 若有元素被移除，此操作会改变原有实例集合。   迭代器（Iterator）：  以内部类的方式遍历集合中的元素，有以下方法：  hasNext()； next()； remove()；   构造思路：  写一个 iterator() 方法返回一个自己的迭代器， 创建一个自己的迭代器继承 Iterator 接口，重写接口的三个方法。 使用时：用 iterator() 创建迭代器，再用迭代器去调用其中的三个方法。      2.</description>
    </item>
    
    <item>
      <title>Maven：生命周期、插件及包管理</title>
      <link>https://hoffmanzheng.github.io/2019/maven/</link>
      <pubDate>Sun, 29 Dec 2019 23:37:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2019/maven/</guid>
      <description>Maven 作为一个强大的项目管理工具，在项目清理、开发、部署时有着强大的功能。此外，Maven 还可以自动管理 Java 包的传递性依赖，解决包的依赖冲突并对依赖的 scope 进行控制。 本篇对其功能和用法做简单的介绍。
Maven 的生命周期 1. Maven 简介 Maven 是一个项目管理工具，它包含了一个项目对象模型（Project Object Model），反映在配置中，就是一个 pom.xml 文件。是一组标准集合，一个项目的生命周期、一个包依赖管理系统。
当我们使用 Maven 的时候，通过一个自定义的项目对象模型，pom.xml 来详细描述我们自己的项目。
2. Maven 的生命周期 Maven 有三个内置的构建生命周期：default生命周期处理你的项目开发，clean 生命周期负责清理，而 site  生命周期处理项目站点文档的创建。
具体的生命周期及其顺序可参见 Apache Maven 官方生命周期文档，在我们使用命令调动生命周期的时候，比如 mvn verify，它会按照顺序执行 verify 之前的每个默认的生命周期阶段。
3. Maven 中的插件 Maven 实际上只是 Maven 插件集合的核心框架。插件是大多数操作实际执行的地方，几乎可以想到的对项目的所有操作都是由 Maven 插件来执行的。
Maven 在某个生命周期中执行的职责与该阶段绑定的插件目标 plugin : goal 有关，插件的 goal 代表一个特定的任务。当 maven 的生命周期运行到插件所绑定的阶段时，便会运行该阶段内所声明的插件任务。
插件的配置可以参考 Apache Maven 官方插件配置指南，下图以 spotbugs 插件为例图示插件在 pom.xml 文件中的配置。
Maven 下的 Java 包管理 1.</description>
    </item>
    
    <item>
      <title>Git 与 GitHub 使用指北</title>
      <link>https://hoffmanzheng.github.io/2019/git/</link>
      <pubDate>Thu, 26 Dec 2019 21:49:47 +0100</pubDate>
      
      <guid>https://hoffmanzheng.github.io/2019/git/</guid>
      <description>本篇介绍实用的工具 Git 及 GitHub 的常用功能及其操作，如：代码的版本控制，远程备份，团队项目协作等。
Git 本地仓库 Git 工作流程：
0. 应用场景  代码版本管理 / 多版本代码开发 / 多版本代码合并  1. 安装 Git 参考伯克利课程 CS61b 中的教程安装 Git
2. 配置 Git git config --global user.name + 你的英文名 git config --global user.email + 你的邮箱 git config --global push.default simple git config --global core.quotepath false // 不会对0×80以上的字符进行quote，中文显示正常。 git config --global core.editor &amp;#34;vim&amp;#34; git config --global core.autocrlf input git config --global --list // 查看当前配置列表 vi ~/.gitconfig // 编辑配置文件 3.</description>
    </item>
    
  </channel>
</rss>
